{
  "version": "1.0.0",
  "generatedAt": "2026-02-12T00:46:55.077Z",
  "sources": {
    "litellm": {
      "fetchedAt": "2026-02-12T00:46:55.077Z",
      "modelCount": 1142
    },
    "openrouter": {
      "fetchedAt": "2026-02-12T00:46:55.077Z",
      "modelCount": 116
    }
  },
  "models": {
    "1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0": {
      "provider": "bedrock",
      "displayName": "1024 X 1024/50 Steps/bedrock/amazon.nova Canvas V1:0",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 2600
      }
    },
    "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1": {
      "provider": "bedrock",
      "displayName": "1024 X 1024/50 Steps/stability.stable Diffusion Xl V1",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "1024-x-1024/dall-e-2": {
      "provider": "openai",
      "displayName": "1024 X 1024/dall E 2",
      "mode": "image_generation",
      "source": "litellm"
    },
    "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1": {
      "provider": "bedrock",
      "displayName": "1024 X 1024/max Steps/stability.stable Diffusion Xl V1",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "256-x-256/dall-e-2": {
      "provider": "openai",
      "displayName": "256 X 256/dall E 2",
      "mode": "image_generation",
      "source": "litellm"
    },
    "512-x-512/50-steps/stability.stable-diffusion-xl-v0": {
      "provider": "bedrock",
      "displayName": "512 X 512/50 Steps/stability.stable Diffusion Xl V0",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "512-x-512/dall-e-2": {
      "provider": "openai",
      "displayName": "512 X 512/dall E 2",
      "mode": "image_generation",
      "source": "litellm"
    },
    "512-x-512/max-steps/stability.stable-diffusion-xl-v0": {
      "provider": "bedrock",
      "displayName": "512 X 512/max Steps/stability.stable Diffusion Xl V0",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "ai21.j2-mid-v1": {
      "provider": "bedrock",
      "displayName": "Ai21.j2 Mid V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000125,
        "outputCostPerToken": 0.0000125
      },
      "context": {
        "maxInputTokens": 8191,
        "maxOutputTokens": 8191
      }
    },
    "ai21.j2-ultra-v1": {
      "provider": "bedrock",
      "displayName": "Ai21.j2 Ultra V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000188,
        "outputCostPerToken": 0.0000188
      },
      "context": {
        "maxInputTokens": 8191,
        "maxOutputTokens": 8191
      }
    },
    "ai21.jamba-1-5-large-v1:0": {
      "provider": "bedrock",
      "displayName": "Ai21.jamba 1 5 Large V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "ai21.jamba-1-5-mini-v1:0": {
      "provider": "bedrock",
      "displayName": "Ai21.jamba 1 5 Mini V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 4e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "ai21.jamba-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Ai21.jamba Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 7e-7
      },
      "context": {
        "maxInputTokens": 70000,
        "maxOutputTokens": 4096
      }
    },
    "amazon.nova-canvas-v1:0": {
      "provider": "bedrock",
      "displayName": "Amazon.nova Canvas V1:0",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 2600
      }
    },
    "amazon.nova-2-multimodal-embeddings-v1:0": {
      "provider": "bedrock",
      "displayName": "Amazon.nova 2 Multimodal Embeddings V1:0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.35e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8172
      },
      "capabilities": {
        "audioInput": true
      }
    },
    "amazon.rerank-v1:0": {
      "provider": "bedrock",
      "displayName": "Amazon.rerank V1:0",
      "mode": "rerank",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 32000
      }
    },
    "amazon.titan-embed-image-v1": {
      "provider": "bedrock",
      "displayName": "Amazon.titan Embed Image V1",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 128
      }
    },
    "amazon.titan-embed-text-v1": {
      "provider": "bedrock",
      "displayName": "Amazon.titan Embed Text V1",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8192
      }
    },
    "amazon.titan-embed-text-v2:0": {
      "provider": "bedrock",
      "displayName": "Amazon.titan Embed Text V2:0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8192
      }
    },
    "amazon.titan-image-generator-v1": {
      "provider": "bedrock",
      "displayName": "Amazon.titan Image Generator V1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "amazon.titan-image-generator-v2": {
      "provider": "bedrock",
      "displayName": "Amazon.titan Image Generator V2",
      "mode": "image_generation",
      "source": "litellm"
    },
    "amazon.titan-image-generator-v2:0": {
      "provider": "bedrock",
      "displayName": "Amazon.titan Image Generator V2:0",
      "mode": "image_generation",
      "source": "litellm"
    },
    "twelvelabs.marengo-embed-2-7-v1:0": {
      "provider": "bedrock",
      "displayName": "Twelvelabs.marengo Embed 2 7 V1:0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00007,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 77
      }
    },
    "us.twelvelabs.marengo-embed-2-7-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.twelvelabs.marengo Embed 2 7 V1:0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00007,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 77
      }
    },
    "eu.twelvelabs.marengo-embed-2-7-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu.twelvelabs.marengo Embed 2 7 V1:0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00007,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 77
      }
    },
    "twelvelabs.pegasus-1-2-v1:0": {
      "provider": "bedrock",
      "displayName": "Twelvelabs.pegasus 1 2 V1:0",
      "mode": "chat",
      "source": "litellm"
    },
    "us.twelvelabs.pegasus-1-2-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.twelvelabs.pegasus 1 2 V1:0",
      "mode": "chat",
      "source": "litellm"
    },
    "eu.twelvelabs.pegasus-1-2-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu.twelvelabs.pegasus 1 2 V1:0",
      "mode": "chat",
      "source": "litellm"
    },
    "amazon.titan-text-express-v1": {
      "provider": "bedrock",
      "displayName": "Amazon.titan Text Express V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000013,
        "outputCostPerToken": 0.0000017
      },
      "context": {
        "maxInputTokens": 42000,
        "maxOutputTokens": 8000
      }
    },
    "amazon.titan-text-lite-v1": {
      "provider": "bedrock",
      "displayName": "Amazon.titan Text Lite V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 4e-7
      },
      "context": {
        "maxInputTokens": 42000,
        "maxOutputTokens": 4000
      }
    },
    "amazon.titan-text-premier-v1:0": {
      "provider": "bedrock",
      "displayName": "Amazon.titan Text Premier V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 42000,
        "maxOutputTokens": 32000
      }
    },
    "anthropic.claude-3-5-haiku-20241022-v1:0": {
      "provider": "bedrock",
      "displayName": "Anthropic.claude 3 5 Haiku 20241022 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0.000004,
        "cacheCreationCostPerToken": 0.000001,
        "cacheReadCostPerToken": 8e-8
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "provider": "bedrock",
      "displayName": "Anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "provider": "bedrock",
      "displayName": "Anthropic.claude 3 5 Sonnet 20241022 V2:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "anthropic.claude-3-7-sonnet-20240620-v1:0": {
      "provider": "bedrock",
      "displayName": "Anthropic.claude 3 7 Sonnet 20240620 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000036,
        "outputCostPerToken": 0.000018,
        "cacheCreationCostPerToken": 0.0000045,
        "cacheReadCostPerToken": 3.6e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "anthropic.claude-3-haiku-20240307-v1:0": {
      "provider": "bedrock",
      "displayName": "Anthropic.claude 3 Haiku 20240307 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "anthropic.claude-3-opus-20240229-v1:0": {
      "provider": "bedrock",
      "displayName": "Anthropic.claude 3 Opus 20240229 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "anthropic.claude-3-sonnet-20240229-v1:0": {
      "provider": "bedrock",
      "displayName": "Anthropic.claude 3 Sonnet 20240229 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0.0000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "apac.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "provider": "bedrock",
      "displayName": "Apac.anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "apac.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "provider": "bedrock",
      "displayName": "Apac.anthropic.claude 3 5 Sonnet 20241022 V2:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "apac.anthropic.claude-3-haiku-20240307-v1:0": {
      "provider": "bedrock",
      "displayName": "Apac.anthropic.claude 3 Haiku 20240307 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "apac.anthropic.claude-3-sonnet-20240229-v1:0": {
      "provider": "bedrock",
      "displayName": "Apac.anthropic.claude 3 Sonnet 20240229 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "ada": {
      "provider": "azure",
      "displayName": "Ada",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8191
      }
    },
    "codex-mini": {
      "provider": "azure",
      "displayName": "Codex Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000015,
        "outputCostPerToken": 0.000006,
        "cacheReadCostPerToken": 3.75e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "command-r-plus": {
      "provider": "azure",
      "displayName": "Command R Plus",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "computer-use-preview": {
      "provider": "azure",
      "displayName": "Computer Use Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000012
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 1024
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": false,
        "reasoning": true
      }
    },
    "container": {
      "provider": "azure",
      "displayName": "Container",
      "mode": "chat",
      "source": "litellm"
    },
    "eu/gpt-4o-2024-08-06": {
      "provider": "azure",
      "displayName": "Eu/gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000275,
        "outputCostPerToken": 0.000011,
        "cacheReadCostPerToken": 0.000001375
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      },
      "deprecationDate": "2026-02-27"
    },
    "eu/gpt-4o-2024-11-20": {
      "provider": "azure",
      "displayName": "Eu/gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000275,
        "outputCostPerToken": 0.000011,
        "cacheCreationCostPerToken": 0.00000138
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2026-03-01"
    },
    "eu/gpt-4o-mini-2024-07-18": {
      "provider": "azure",
      "displayName": "Eu/gpt 4o Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.65e-7,
        "outputCostPerToken": 6.6e-7,
        "cacheReadCostPerToken": 8.3e-8
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      }
    },
    "eu/gpt-4o-mini-realtime-preview-2024-12-17": {
      "provider": "azure",
      "displayName": "Eu/gpt 4o Mini Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6.6e-7,
        "outputCostPerToken": 0.00000264,
        "cacheReadCostPerToken": 3.3e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "eu/gpt-4o-realtime-preview-2024-10-01": {
      "provider": "azure",
      "displayName": "Eu/gpt 4o Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000055,
        "outputCostPerToken": 0.000022,
        "cacheReadCostPerToken": 0.00000275
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "eu/gpt-4o-realtime-preview-2024-12-17": {
      "provider": "azure",
      "displayName": "Eu/gpt 4o Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000055,
        "outputCostPerToken": 0.000022,
        "cacheReadCostPerToken": 0.00000275
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "eu/gpt-5-2025-08-07": {
      "provider": "azure",
      "displayName": "Eu/gpt 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001375,
        "outputCostPerToken": 0.000011,
        "cacheReadCostPerToken": 1.375e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "eu/gpt-5-mini-2025-08-07": {
      "provider": "azure",
      "displayName": "Eu/gpt 5 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.75e-7,
        "outputCostPerToken": 0.0000022,
        "cacheReadCostPerToken": 2.75e-8
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "eu/gpt-5.1": {
      "provider": "azure",
      "displayName": "Eu/gpt 5.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000138,
        "outputCostPerToken": 0.000011,
        "cacheReadCostPerToken": 1.4e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "eu/gpt-5.1-chat": {
      "provider": "azure",
      "displayName": "Eu/gpt 5.1 Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000138,
        "outputCostPerToken": 0.000011,
        "cacheReadCostPerToken": 1.4e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "eu/gpt-5.1-codex": {
      "provider": "azure",
      "displayName": "Eu/gpt 5.1 Codex",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000138,
        "outputCostPerToken": 0.000011,
        "cacheReadCostPerToken": 1.4e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "eu/gpt-5.1-codex-mini": {
      "provider": "azure",
      "displayName": "Eu/gpt 5.1 Codex Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.75e-7,
        "outputCostPerToken": 0.0000022,
        "cacheReadCostPerToken": 2.8e-8
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "eu/gpt-5-nano-2025-08-07": {
      "provider": "azure",
      "displayName": "Eu/gpt 5 Nano",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.5e-8,
        "outputCostPerToken": 4.4e-7,
        "cacheReadCostPerToken": 5.5e-9
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "eu/o1-2024-12-17": {
      "provider": "azure",
      "displayName": "Eu/o1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000165,
        "outputCostPerToken": 0.000066,
        "cacheReadCostPerToken": 0.00000825
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true
      }
    },
    "eu/o1-mini-2024-09-12": {
      "provider": "azure",
      "displayName": "Eu/o1 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000121,
        "outputCostPerToken": 0.00000484,
        "cacheReadCostPerToken": 6.05e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true
      }
    },
    "eu/o1-preview-2024-09-12": {
      "provider": "azure",
      "displayName": "Eu/o1 Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000165,
        "outputCostPerToken": 0.000066,
        "cacheReadCostPerToken": 0.00000825
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true
      }
    },
    "eu/o3-mini-2025-01-31": {
      "provider": "azure",
      "displayName": "Eu/o3 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000121,
        "outputCostPerToken": 0.00000484,
        "cacheReadCostPerToken": 6.05e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": false,
        "promptCaching": true,
        "reasoning": true
      }
    },
    "global-standard/gpt-4o-2024-08-06": {
      "provider": "azure",
      "displayName": "Global Standard/gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      },
      "deprecationDate": "2026-02-27"
    },
    "global-standard/gpt-4o-2024-11-20": {
      "provider": "azure",
      "displayName": "Global Standard/gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2026-03-01"
    },
    "global-standard/gpt-4o-mini": {
      "provider": "azure",
      "displayName": "Global Standard/gpt 4o Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "global/gpt-4o-2024-08-06": {
      "provider": "azure",
      "displayName": "Global/gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      },
      "deprecationDate": "2026-02-27"
    },
    "global/gpt-4o-2024-11-20": {
      "provider": "azure",
      "displayName": "Global/gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      },
      "deprecationDate": "2026-03-01"
    },
    "global/gpt-5.1": {
      "provider": "azure",
      "displayName": "Global/gpt 5.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "global/gpt-5.1-chat": {
      "provider": "azure",
      "displayName": "Global/gpt 5.1 Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "global/gpt-5.1-codex": {
      "provider": "azure",
      "displayName": "Global/gpt 5.1 Codex",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "global/gpt-5.1-codex-mini": {
      "provider": "azure",
      "displayName": "Global/gpt 5.1 Codex Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.000002,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-3.5-turbo": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-3.5 Turbo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 16385,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-3.5-turbo-0125": {
      "provider": "openai",
      "displayName": "Gpt 3.5 Turbo 0125",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 16385,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true
      }
    },
    "gpt-35-turbo": {
      "provider": "azure",
      "displayName": "Gpt 35 Turbo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 4097,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "gpt-35-turbo-0125": {
      "provider": "azure",
      "displayName": "Gpt 35 Turbo 0125",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      },
      "deprecationDate": "2025-05-31"
    },
    "gpt-35-turbo-0301": {
      "provider": "azure",
      "displayName": "Gpt 35 Turbo 0301",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 4097,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      },
      "deprecationDate": "2025-02-13"
    },
    "gpt-35-turbo-0613": {
      "provider": "azure",
      "displayName": "Gpt 35 Turbo 0613",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000015,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 4097,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      },
      "deprecationDate": "2025-02-13"
    },
    "gpt-35-turbo-1106": {
      "provider": "azure",
      "displayName": "Gpt 35 Turbo 1106",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      },
      "deprecationDate": "2025-03-31"
    },
    "gpt-35-turbo-16k": {
      "provider": "azure",
      "displayName": "Gpt 35 Turbo 16k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000004
      },
      "context": {
        "maxInputTokens": 16385,
        "maxOutputTokens": 4096
      }
    },
    "gpt-35-turbo-16k-0613": {
      "provider": "azure",
      "displayName": "Gpt 35 Turbo 16k 0613",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000004
      },
      "context": {
        "maxInputTokens": 16385,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "gpt-4": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00003,
        "outputCostPerToken": 0.00006
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4-0125-preview": {
      "provider": "openai",
      "displayName": "Gpt 4 0125 Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true
      },
      "deprecationDate": "2026-03-26"
    },
    "gpt-4-0613": {
      "provider": "openai",
      "displayName": "Gpt 4 0613",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00003,
        "outputCostPerToken": 0.00006
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true
      },
      "deprecationDate": "2025-06-06"
    },
    "gpt-4-1106-preview": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4 Turbo (older v1106)",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true,
        "structuredOutput": true
      },
      "deprecationDate": "2026-03-26",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4-32k": {
      "provider": "openai",
      "displayName": "Gpt 4 32k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00006,
        "outputCostPerToken": 0.00012
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "promptCaching": true
      }
    },
    "gpt-4-32k-0613": {
      "provider": "openai",
      "displayName": "Gpt 4 32k 0613",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00006,
        "outputCostPerToken": 0.00012
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "promptCaching": true
      }
    },
    "gpt-4-turbo": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4 Turbo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true,
        "pdfInput": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4-turbo-2024-04-09": {
      "provider": "openai",
      "displayName": "Gpt 4 Turbo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "gpt-4-turbo-vision-preview": {
      "provider": "azure",
      "displayName": "Gpt 4 Turbo Vision Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true
      }
    },
    "gpt-4.1": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4.1-2025-04-14": {
      "provider": "openai",
      "displayName": "Gpt 4.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "gpt-4.1-mini": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4.1 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.0000016,
        "cacheReadCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4.1-mini-2025-04-14": {
      "provider": "openai",
      "displayName": "Gpt 4.1 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.0000016,
        "cacheReadCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "gpt-4.1-nano": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4.1 Nano",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 4e-7,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4.1-nano-2025-04-14": {
      "provider": "openai",
      "displayName": "Gpt 4.1 Nano",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 4e-7,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "gpt-4.5-preview": {
      "provider": "openai",
      "displayName": "Gpt 4.5 Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000075,
        "outputCostPerToken": 0.00015,
        "cacheReadCostPerToken": 0.0000375
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "gpt-4o": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4o-2024-05-13": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4o (2024-05-13)",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true,
        "pdfInput": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4o-2024-08-06": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4o (2024-08-06)",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4o-2024-11-20": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4o (2024-11-20)",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-audio-2025-08-28": {
      "provider": "openai",
      "displayName": "Gpt Audio",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": false,
        "promptCaching": false,
        "reasoning": false,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-audio-mini-2025-10-06": {
      "provider": "openai",
      "displayName": "Gpt Audio Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000024
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": false,
        "promptCaching": false,
        "reasoning": false,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-audio-preview-2024-12-17": {
      "provider": "openai",
      "displayName": "Gpt 4o Audio Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-mini": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4o-mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4o-mini-2024-07-18": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4o-mini (2024-07-18)",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4o-mini-audio-preview-2024-12-17": {
      "provider": "openai",
      "displayName": "Gpt 4o Mini Audio Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-mini-realtime-preview-2024-12-17": {
      "provider": "openai",
      "displayName": "Gpt 4o Mini Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000024,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-realtime-2025-08-28": {
      "provider": "openai",
      "displayName": "Gpt Realtime",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000004,
        "outputCostPerToken": 0.000016,
        "cacheReadCostPerToken": 4e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-realtime-mini-2025-10-06": {
      "provider": "azure",
      "displayName": "Gpt Realtime Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000024,
        "cacheReadCostPerToken": 6e-8
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-mini-transcribe": {
      "provider": "openai",
      "displayName": "Gpt 4o Mini Transcribe",
      "mode": "audio_transcription",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 16000,
        "maxOutputTokens": 2000
      }
    },
    "gpt-4o-mini-tts": {
      "provider": "openai",
      "displayName": "Gpt 4o Mini Tts",
      "mode": "audio_speech",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      }
    },
    "gpt-4o-realtime-preview-2024-10-01": {
      "provider": "openai",
      "displayName": "Gpt 4o Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.00002,
        "cacheReadCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-realtime-preview-2024-12-17": {
      "provider": "openai",
      "displayName": "Gpt 4o Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.00002,
        "cacheReadCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-transcribe": {
      "provider": "openai",
      "displayName": "Gpt 4o Transcribe",
      "mode": "audio_transcription",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 16000,
        "maxOutputTokens": 2000
      }
    },
    "gpt-4o-transcribe-diarize": {
      "provider": "openai",
      "displayName": "Gpt 4o Transcribe Diarize",
      "mode": "audio_transcription",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 16000,
        "maxOutputTokens": 2000
      }
    },
    "gpt-5.1-2025-11-13": {
      "provider": "openai",
      "displayName": "Gpt 5.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5.1-chat-2025-11-13": {
      "provider": "azure",
      "displayName": "Gpt 5.1 Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": false,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5.1-codex-2025-11-13": {
      "provider": "azure",
      "displayName": "Gpt 5.1 Codex",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5.1-codex-mini-2025-11-13": {
      "provider": "azure",
      "displayName": "Gpt 5.1 Codex Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.000002,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5-2025-08-07": {
      "provider": "openai",
      "displayName": "Gpt 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5-chat": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5 Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": false,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5-chat-latest": {
      "provider": "openai",
      "displayName": "Gpt 5 Chat Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": false,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5-codex": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5 Codex",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5-mini": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.000002,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5-mini-2025-08-07": {
      "provider": "openai",
      "displayName": "Gpt 5 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.000002,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5-nano": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5 Nano",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-8,
        "outputCostPerToken": 4e-7,
        "cacheReadCostPerToken": 5e-9
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5-nano-2025-08-07": {
      "provider": "openai",
      "displayName": "Gpt 5 Nano",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-8,
        "outputCostPerToken": 4e-7,
        "cacheReadCostPerToken": 5e-9
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5-pro": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.00012
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true,
        "webSearch": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5.1": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5.1-chat": {
      "provider": "azure",
      "displayName": "OpenAI: GPT-5.1 Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5.1-codex": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5.1-Codex",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5.1-codex-max": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5.1-Codex-Max",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5.1-codex-mini": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5.1-Codex-Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.000002,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5.2": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5.2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000175,
        "outputCostPerToken": 0.000014,
        "cacheReadCostPerToken": 1.75e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5.2-2025-12-11": {
      "provider": "openai",
      "displayName": "Gpt 5.2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000175,
        "outputCostPerToken": 0.000014,
        "cacheReadCostPerToken": 1.75e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5.2-chat": {
      "provider": "azure",
      "displayName": "OpenAI: GPT-5.2 Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000175,
        "outputCostPerToken": 0.000014,
        "cacheReadCostPerToken": 1.75e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5.2-chat-2025-12-11": {
      "provider": "azure",
      "displayName": "Gpt 5.2 Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000175,
        "outputCostPerToken": 0.000014,
        "cacheReadCostPerToken": 1.75e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5.2-codex": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5.2-Codex",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000175,
        "outputCostPerToken": 0.000014,
        "cacheReadCostPerToken": 1.75e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty"
      ]
    },
    "gpt-5.2-pro": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5.2 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000021,
        "outputCostPerToken": 0.000168
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true,
        "webSearch": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-5.2-pro-2025-12-11": {
      "provider": "openai",
      "displayName": "Gpt 5.2 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000021,
        "outputCostPerToken": 0.000168
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true,
        "webSearch": true
      }
    },
    "gpt-image-1": {
      "provider": "openai",
      "displayName": "Gpt Image 1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "hd/1024-x-1024/dall-e-3": {
      "provider": "openai",
      "displayName": "Hd/1024 X 1024/dall E 3",
      "mode": "image_generation",
      "source": "litellm"
    },
    "hd/1024-x-1792/dall-e-3": {
      "provider": "openai",
      "displayName": "Hd/1024 X 1792/dall E 3",
      "mode": "image_generation",
      "source": "litellm"
    },
    "hd/1792-x-1024/dall-e-3": {
      "provider": "openai",
      "displayName": "Hd/1792 X 1024/dall E 3",
      "mode": "image_generation",
      "source": "litellm"
    },
    "high/1024-x-1024/gpt-image-1": {
      "provider": "openai",
      "displayName": "High/1024 X 1024/gpt Image 1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "high/1024-x-1536/gpt-image-1": {
      "provider": "openai",
      "displayName": "High/1024 X 1536/gpt Image 1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "high/1536-x-1024/gpt-image-1": {
      "provider": "openai",
      "displayName": "High/1536 X 1024/gpt Image 1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "low/1024-x-1024/gpt-image-1": {
      "provider": "openai",
      "displayName": "Low/1024 X 1024/gpt Image 1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "low/1024-x-1536/gpt-image-1": {
      "provider": "openai",
      "displayName": "Low/1024 X 1536/gpt Image 1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "low/1536-x-1024/gpt-image-1": {
      "provider": "openai",
      "displayName": "Low/1536 X 1024/gpt Image 1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "medium/1024-x-1024/gpt-image-1": {
      "provider": "openai",
      "displayName": "Medium/1024 X 1024/gpt Image 1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "medium/1024-x-1536/gpt-image-1": {
      "provider": "openai",
      "displayName": "Medium/1024 X 1536/gpt Image 1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "medium/1536-x-1024/gpt-image-1": {
      "provider": "openai",
      "displayName": "Medium/1536 X 1024/gpt Image 1",
      "mode": "image_generation",
      "source": "litellm"
    },
    "gpt-image-1-mini": {
      "provider": "openai",
      "displayName": "Gpt Image 1 Mini",
      "mode": "image_generation",
      "source": "litellm"
    },
    "gpt-image-1.5": {
      "provider": "openai",
      "displayName": "Gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "Gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "low/1024-x-1024/gpt-image-1-mini": {
      "provider": "openai",
      "displayName": "Low/1024 X 1024/gpt Image 1 Mini",
      "mode": "image_generation",
      "source": "litellm"
    },
    "low/1024-x-1536/gpt-image-1-mini": {
      "provider": "openai",
      "displayName": "Low/1024 X 1536/gpt Image 1 Mini",
      "mode": "image_generation",
      "source": "litellm"
    },
    "low/1536-x-1024/gpt-image-1-mini": {
      "provider": "openai",
      "displayName": "Low/1536 X 1024/gpt Image 1 Mini",
      "mode": "image_generation",
      "source": "litellm"
    },
    "medium/1024-x-1024/gpt-image-1-mini": {
      "provider": "openai",
      "displayName": "Medium/1024 X 1024/gpt Image 1 Mini",
      "mode": "image_generation",
      "source": "litellm"
    },
    "medium/1024-x-1536/gpt-image-1-mini": {
      "provider": "openai",
      "displayName": "Medium/1024 X 1536/gpt Image 1 Mini",
      "mode": "image_generation",
      "source": "litellm"
    },
    "medium/1536-x-1024/gpt-image-1-mini": {
      "provider": "openai",
      "displayName": "Medium/1536 X 1024/gpt Image 1 Mini",
      "mode": "image_generation",
      "source": "litellm"
    },
    "high/1024-x-1024/gpt-image-1-mini": {
      "provider": "azure",
      "displayName": "High/1024 X 1024/gpt Image 1 Mini",
      "mode": "image_generation",
      "source": "litellm"
    },
    "high/1024-x-1536/gpt-image-1-mini": {
      "provider": "azure",
      "displayName": "High/1024 X 1536/gpt Image 1 Mini",
      "mode": "image_generation",
      "source": "litellm"
    },
    "high/1536-x-1024/gpt-image-1-mini": {
      "provider": "azure",
      "displayName": "High/1536 X 1024/gpt Image 1 Mini",
      "mode": "image_generation",
      "source": "litellm"
    },
    "mistral-large-2402": {
      "provider": "azure",
      "displayName": "Mistral Large 2402",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 32000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "mistral-large-latest": {
      "provider": "azure",
      "displayName": "Mistral Large Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 32000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "o1": {
      "provider": "openai",
      "displayName": "OpenAI: o1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.00006,
        "cacheReadCostPerToken": 0.0000075
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "o1-2024-12-17": {
      "provider": "openai",
      "displayName": "O1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.00006,
        "cacheReadCostPerToken": 0.0000075
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "o1-mini": {
      "provider": "openai",
      "displayName": "o1 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000011,
        "outputCostPerToken": 0.0000044,
        "cacheReadCostPerToken": 5.5e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "vision": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "o1-mini-2024-09-12": {
      "provider": "openai",
      "displayName": "O1 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000012,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "vision": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "deprecationDate": "2025-10-27"
    },
    "o1-preview": {
      "provider": "openai",
      "displayName": "o1 Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.00006,
        "cacheReadCostPerToken": 0.0000075
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "o1-preview-2024-09-12": {
      "provider": "openai",
      "displayName": "O1 Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.00006,
        "cacheReadCostPerToken": 0.0000075
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "o3": {
      "provider": "openai",
      "displayName": "OpenAI: o3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "o3-2025-04-16": {
      "provider": "openai",
      "displayName": "O3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "o3-deep-research": {
      "provider": "openai",
      "displayName": "OpenAI: o3 Deep Research",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00004,
        "cacheReadCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "o3-mini": {
      "provider": "openai",
      "displayName": "OpenAI: o3 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000011,
        "outputCostPerToken": 0.0000044,
        "cacheReadCostPerToken": 5.5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "o3-mini-2025-01-31": {
      "provider": "openai",
      "displayName": "O3 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000011,
        "outputCostPerToken": 0.0000044,
        "cacheReadCostPerToken": 5.5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true
      }
    },
    "o3-pro": {
      "provider": "openai",
      "displayName": "OpenAI: o3 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00002,
        "outputCostPerToken": 0.00008
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "o3-pro-2025-06-10": {
      "provider": "openai",
      "displayName": "O3 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00002,
        "outputCostPerToken": 0.00008
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "o4-mini": {
      "provider": "openai",
      "displayName": "OpenAI: o4 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000011,
        "outputCostPerToken": 0.0000044,
        "cacheReadCostPerToken": 2.75e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "o4-mini-2025-04-16": {
      "provider": "openai",
      "displayName": "O4 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000011,
        "outputCostPerToken": 0.0000044,
        "cacheReadCostPerToken": 2.75e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "standard/1024-x-1024/dall-e-2": {
      "provider": "azure",
      "displayName": "Standard/1024 X 1024/dall E 2",
      "mode": "image_generation",
      "source": "litellm"
    },
    "standard/1024-x-1024/dall-e-3": {
      "provider": "openai",
      "displayName": "Standard/1024 X 1024/dall E 3",
      "mode": "image_generation",
      "source": "litellm"
    },
    "standard/1024-x-1792/dall-e-3": {
      "provider": "openai",
      "displayName": "Standard/1024 X 1792/dall E 3",
      "mode": "image_generation",
      "source": "litellm"
    },
    "standard/1792-x-1024/dall-e-3": {
      "provider": "openai",
      "displayName": "Standard/1792 X 1024/dall E 3",
      "mode": "image_generation",
      "source": "litellm"
    },
    "text-embedding-3-large": {
      "provider": "openai",
      "displayName": "Text Embedding 3 Large",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.3e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8191
      }
    },
    "text-embedding-3-small": {
      "provider": "openai",
      "displayName": "Text Embedding 3 Small",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-8,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8191
      }
    },
    "text-embedding-ada-002": {
      "provider": "openai",
      "displayName": "Text Embedding Ada 002",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8191
      }
    },
    "speech/azure-tts": {
      "provider": "azure",
      "displayName": "Speech/azure Tts",
      "mode": "audio_speech",
      "source": "litellm"
    },
    "speech/azure-tts-hd": {
      "provider": "azure",
      "displayName": "Speech/azure Tts Hd",
      "mode": "audio_speech",
      "source": "litellm"
    },
    "tts-1": {
      "provider": "openai",
      "displayName": "TTS-1",
      "mode": "audio_speech",
      "source": "litellm"
    },
    "tts-1-hd": {
      "provider": "openai",
      "displayName": "TTS-1 HD",
      "mode": "audio_speech",
      "source": "litellm"
    },
    "us/gpt-4.1-2025-04-14": {
      "provider": "azure",
      "displayName": "Us/gpt 4.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000022,
        "outputCostPerToken": 0.0000088,
        "cacheReadCostPerToken": 5.5e-7
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "webSearch": false
      },
      "deprecationDate": "2026-11-04"
    },
    "us/gpt-4.1-mini-2025-04-14": {
      "provider": "azure",
      "displayName": "Us/gpt 4.1 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4.4e-7,
        "outputCostPerToken": 0.00000176,
        "cacheReadCostPerToken": 1.1e-7
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "webSearch": false
      },
      "deprecationDate": "2026-11-04"
    },
    "us/gpt-4.1-nano-2025-04-14": {
      "provider": "azure",
      "displayName": "Us/gpt 4.1 Nano",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.1e-7,
        "outputCostPerToken": 4.4e-7,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      },
      "deprecationDate": "2026-11-04"
    },
    "us/gpt-4o-2024-08-06": {
      "provider": "azure",
      "displayName": "Us/gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000275,
        "outputCostPerToken": 0.000011,
        "cacheReadCostPerToken": 0.000001375
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      },
      "deprecationDate": "2026-02-27"
    },
    "us/gpt-4o-2024-11-20": {
      "provider": "azure",
      "displayName": "Us/gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000275,
        "outputCostPerToken": 0.000011,
        "cacheCreationCostPerToken": 0.00000138
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2026-03-01"
    },
    "us/gpt-4o-mini-2024-07-18": {
      "provider": "azure",
      "displayName": "Us/gpt 4o Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.65e-7,
        "outputCostPerToken": 6.6e-7,
        "cacheReadCostPerToken": 8.3e-8
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      }
    },
    "us/gpt-4o-mini-realtime-preview-2024-12-17": {
      "provider": "azure",
      "displayName": "Us/gpt 4o Mini Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6.6e-7,
        "outputCostPerToken": 0.00000264,
        "cacheReadCostPerToken": 3.3e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "us/gpt-4o-realtime-preview-2024-10-01": {
      "provider": "azure",
      "displayName": "Us/gpt 4o Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000055,
        "outputCostPerToken": 0.000022,
        "cacheReadCostPerToken": 0.00000275
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "us/gpt-4o-realtime-preview-2024-12-17": {
      "provider": "azure",
      "displayName": "Us/gpt 4o Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000055,
        "outputCostPerToken": 0.000022,
        "cacheReadCostPerToken": 0.00000275
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "us/gpt-5-2025-08-07": {
      "provider": "azure",
      "displayName": "Us/gpt 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001375,
        "outputCostPerToken": 0.000011,
        "cacheReadCostPerToken": 1.375e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us/gpt-5-mini-2025-08-07": {
      "provider": "azure",
      "displayName": "Us/gpt 5 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.75e-7,
        "outputCostPerToken": 0.0000022,
        "cacheReadCostPerToken": 2.75e-8
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us/gpt-5-nano-2025-08-07": {
      "provider": "azure",
      "displayName": "Us/gpt 5 Nano",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.5e-8,
        "outputCostPerToken": 4.4e-7,
        "cacheReadCostPerToken": 5.5e-9
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us/gpt-5.1": {
      "provider": "azure",
      "displayName": "Us/gpt 5.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000138,
        "outputCostPerToken": 0.000011,
        "cacheReadCostPerToken": 1.4e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us/gpt-5.1-chat": {
      "provider": "azure",
      "displayName": "Us/gpt 5.1 Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000138,
        "outputCostPerToken": 0.000011,
        "cacheReadCostPerToken": 1.4e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us/gpt-5.1-codex": {
      "provider": "azure",
      "displayName": "Us/gpt 5.1 Codex",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000138,
        "outputCostPerToken": 0.000011,
        "cacheReadCostPerToken": 1.4e-7
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us/gpt-5.1-codex-mini": {
      "provider": "azure",
      "displayName": "Us/gpt 5.1 Codex Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.75e-7,
        "outputCostPerToken": 0.0000022,
        "cacheReadCostPerToken": 2.8e-8
      },
      "context": {
        "maxInputTokens": 272000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us/o1-2024-12-17": {
      "provider": "azure",
      "displayName": "Us/o1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000165,
        "outputCostPerToken": 0.000066,
        "cacheReadCostPerToken": 0.00000825
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true
      }
    },
    "us/o1-mini-2024-09-12": {
      "provider": "azure",
      "displayName": "Us/o1 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000121,
        "outputCostPerToken": 0.00000484,
        "cacheReadCostPerToken": 6.05e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true
      }
    },
    "us/o1-preview-2024-09-12": {
      "provider": "azure",
      "displayName": "Us/o1 Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000165,
        "outputCostPerToken": 0.000066,
        "cacheReadCostPerToken": 0.00000825
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true
      }
    },
    "us/o3-2025-04-16": {
      "provider": "azure",
      "displayName": "Us/o3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000022,
        "outputCostPerToken": 0.0000088,
        "cacheReadCostPerToken": 5.5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true
      },
      "deprecationDate": "2026-04-16"
    },
    "us/o3-mini-2025-01-31": {
      "provider": "azure",
      "displayName": "Us/o3 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000121,
        "outputCostPerToken": 0.00000484,
        "cacheReadCostPerToken": 6.05e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": false,
        "promptCaching": true,
        "reasoning": true
      }
    },
    "us/o4-mini-2025-04-16": {
      "provider": "azure",
      "displayName": "Us/o4 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000121,
        "outputCostPerToken": 0.00000484,
        "cacheReadCostPerToken": 3.1e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true
      }
    },
    "whisper-1": {
      "provider": "openai",
      "displayName": "Whisper",
      "mode": "audio_transcription",
      "source": "litellm"
    },
    "*/1-month-commitment/cohere.command-light-text-v14": {
      "provider": "bedrock",
      "displayName": "*/1 Month Commitment/cohere.command Light Text V14",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "*/1-month-commitment/cohere.command-text-v14": {
      "provider": "bedrock",
      "displayName": "*/1 Month Commitment/cohere.command Text V14",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "*/6-month-commitment/cohere.command-light-text-v14": {
      "provider": "bedrock",
      "displayName": "*/6 Month Commitment/cohere.command Light Text V14",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "*/6-month-commitment/cohere.command-text-v14": {
      "provider": "bedrock",
      "displayName": "*/6 Month Commitment/cohere.command Text V14",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Ap Northeast 1/1 Month Commitment/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "ap-northeast-1/1-month-commitment/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Ap Northeast 1/1 Month Commitment/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "ap-northeast-1/1-month-commitment/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Ap Northeast 1/1 Month Commitment/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Ap Northeast 1/6 Month Commitment/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "ap-northeast-1/6-month-commitment/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Ap Northeast 1/6 Month Commitment/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "ap-northeast-1/6-month-commitment/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Ap Northeast 1/6 Month Commitment/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "ap-northeast-1/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Ap Northeast 1/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000223,
        "outputCostPerToken": 0.00000755
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "ap-northeast-1/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Ap Northeast 1/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "ap-northeast-1/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Ap Northeast 1/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "ap-northeast-1/moonshotai.kimi-k2-thinking": {
      "provider": "bedrock",
      "displayName": "Ap Northeast 1/moonshotai.kimi K2 Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.3e-7,
        "outputCostPerToken": 0.00000303
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "moonshotai.kimi-k2-thinking": {
      "provider": "bedrock",
      "displayName": "Moonshotai.kimi K2 Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.3e-7,
        "outputCostPerToken": 0.00000303
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "moonshotai.kimi-k2.5": {
      "provider": "bedrock",
      "displayName": "Moonshotai.kimi K2.5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.3e-7,
        "outputCostPerToken": 0.00000303
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "ap-south-1/meta.llama3-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Ap South 1/meta.llama3 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000318,
        "outputCostPerToken": 0.0000042
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "ap-south-1/meta.llama3-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Ap South 1/meta.llama3 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3.6e-7,
        "outputCostPerToken": 7.2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "ap-south-1/moonshotai.kimi-k2-thinking": {
      "provider": "bedrock",
      "displayName": "Ap South 1/moonshotai.kimi K2 Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.1e-7,
        "outputCostPerToken": 0.00000294
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "ca-central-1/meta.llama3-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Ca Central 1/meta.llama3 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000305,
        "outputCostPerToken": 0.00000403
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "ca-central-1/meta.llama3-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Ca Central 1/meta.llama3 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3.5e-7,
        "outputCostPerToken": 6.9e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "eu-central-1/1-month-commitment/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Eu Central 1/1 Month Commitment/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "eu-central-1/1-month-commitment/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Eu Central 1/1 Month Commitment/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "eu-central-1/1-month-commitment/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Eu Central 1/1 Month Commitment/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "eu-central-1/6-month-commitment/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Eu Central 1/6 Month Commitment/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "eu-central-1/6-month-commitment/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Eu Central 1/6 Month Commitment/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "eu-central-1/6-month-commitment/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Eu Central 1/6 Month Commitment/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "eu-central-1/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Eu Central 1/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000248,
        "outputCostPerToken": 0.00000838
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "eu-central-1/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Eu Central 1/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "eu-central-1/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Eu Central 1/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "eu-west-1/meta.llama3-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu West 1/meta.llama3 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000286,
        "outputCostPerToken": 0.00000378
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "eu-west-1/meta.llama3-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu West 1/meta.llama3 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3.2e-7,
        "outputCostPerToken": 6.5e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "eu-west-2/meta.llama3-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu West 2/meta.llama3 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000345,
        "outputCostPerToken": 0.00000455
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "eu-west-2/meta.llama3-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu West 2/meta.llama3 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3.9e-7,
        "outputCostPerToken": 7.8e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "eu-west-3/mistral.mistral-7b-instruct-v0:2": {
      "provider": "bedrock",
      "displayName": "Eu West 3/mistral.mistral 7b Instruct V0:2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2.6e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      }
    },
    "eu-west-3/mistral.mistral-large-2402-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu West 3/mistral.mistral Large 2402 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000104,
        "outputCostPerToken": 0.0000312
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "eu-west-3/mistral.mixtral-8x7b-instruct-v0:1": {
      "provider": "bedrock",
      "displayName": "Eu West 3/mistral.mixtral 8x7b Instruct V0:1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.9e-7,
        "outputCostPerToken": 9.1e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      }
    },
    "invoke/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "provider": "bedrock",
      "displayName": "Invoke/anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "sa-east-1/meta.llama3-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Sa East 1/meta.llama3 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000445,
        "outputCostPerToken": 0.00000588
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "sa-east-1/meta.llama3-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Sa East 1/meta.llama3 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.00000101
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "sa-east-1/moonshotai.kimi-k2-thinking": {
      "provider": "bedrock",
      "displayName": "Sa East 1/moonshotai.kimi K2 Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.3e-7,
        "outputCostPerToken": 0.00000303
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "us-east-1/1-month-commitment/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Us East 1/1 Month Commitment/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/1-month-commitment/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Us East 1/1 Month Commitment/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/1-month-commitment/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Us East 1/1 Month Commitment/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/6-month-commitment/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Us East 1/6 Month Commitment/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/6-month-commitment/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Us East 1/6 Month Commitment/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/6-month-commitment/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Us East 1/6 Month Commitment/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Us East 1/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0.0000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Us East 1/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Us East 1/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/meta.llama3-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us East 1/meta.llama3 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000265,
        "outputCostPerToken": 0.0000035
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "us-east-1/meta.llama3-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us East 1/meta.llama3 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "us-east-1/mistral.mistral-7b-instruct-v0:2": {
      "provider": "bedrock",
      "displayName": "Us East 1/mistral.mistral 7b Instruct V0:2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/mistral.mistral-large-2402-v1:0": {
      "provider": "bedrock",
      "displayName": "Us East 1/mistral.mistral Large 2402 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "us-east-1/mistral.mixtral-8x7b-instruct-v0:1": {
      "provider": "bedrock",
      "displayName": "Us East 1/mistral.mixtral 8x7b Instruct V0:1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4.5e-7,
        "outputCostPerToken": 7e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      }
    },
    "us-east-1/moonshotai.kimi-k2-thinking": {
      "provider": "bedrock",
      "displayName": "Us East 1/moonshotai.kimi K2 Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "us-east-2/moonshotai.kimi-k2-thinking": {
      "provider": "bedrock",
      "displayName": "Us East 2/moonshotai.kimi K2 Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "us-gov-east-1/amazon.nova-pro-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/amazon.nova Pro V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9.6e-7,
        "outputCostPerToken": 0.00000384
      },
      "context": {
        "maxInputTokens": 300000,
        "maxOutputTokens": 10000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "us-gov-east-1/amazon.titan-embed-text-v1": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/amazon.titan Embed Text V1",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8192
      }
    },
    "us-gov-east-1/amazon.titan-embed-text-v2:0": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/amazon.titan Embed Text V2:0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8192
      }
    },
    "us-gov-east-1/amazon.titan-text-express-v1": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/amazon.titan Text Express V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000013,
        "outputCostPerToken": 0.0000017
      },
      "context": {
        "maxInputTokens": 42000,
        "maxOutputTokens": 8000
      }
    },
    "us-gov-east-1/amazon.titan-text-lite-v1": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/amazon.titan Text Lite V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 4e-7
      },
      "context": {
        "maxInputTokens": 42000,
        "maxOutputTokens": 4000
      }
    },
    "us-gov-east-1/amazon.titan-text-premier-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/amazon.titan Text Premier V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 42000,
        "maxOutputTokens": 32000
      }
    },
    "us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000036,
        "outputCostPerToken": 0.000018
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/anthropic.claude 3 Haiku 20240307 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "us-gov-east-1/claude-sonnet-4-5-20250929-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/claude Sonnet 4 5 20250929 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000033,
        "outputCostPerToken": 0.0000165
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us-gov-east-1/meta.llama3-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/meta.llama3 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000265,
        "outputCostPerToken": 0.0000035
      },
      "context": {
        "maxInputTokens": 8000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "pdfInput": true
      }
    },
    "us-gov-east-1/meta.llama3-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov East 1/meta.llama3 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.00000265
      },
      "context": {
        "maxInputTokens": 8000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "pdfInput": true
      }
    },
    "us-gov-west-1/amazon.nova-pro-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/amazon.nova Pro V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9.6e-7,
        "outputCostPerToken": 0.00000384
      },
      "context": {
        "maxInputTokens": 300000,
        "maxOutputTokens": 10000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "us-gov-west-1/amazon.titan-embed-text-v1": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/amazon.titan Embed Text V1",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8192
      }
    },
    "us-gov-west-1/amazon.titan-embed-text-v2:0": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/amazon.titan Embed Text V2:0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8192
      }
    },
    "us-gov-west-1/amazon.titan-text-express-v1": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/amazon.titan Text Express V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000013,
        "outputCostPerToken": 0.0000017
      },
      "context": {
        "maxInputTokens": 42000,
        "maxOutputTokens": 8000
      }
    },
    "us-gov-west-1/amazon.titan-text-lite-v1": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/amazon.titan Text Lite V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 4e-7
      },
      "context": {
        "maxInputTokens": 42000,
        "maxOutputTokens": 4000
      }
    },
    "us-gov-west-1/amazon.titan-text-premier-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/amazon.titan Text Premier V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 42000,
        "maxOutputTokens": 32000
      }
    },
    "us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/anthropic.claude 3 7 Sonnet 20250219 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000036,
        "outputCostPerToken": 0.000018,
        "cacheCreationCostPerToken": 0.0000045,
        "cacheReadCostPerToken": 3.6e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000036,
        "outputCostPerToken": 0.000018
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/anthropic.claude 3 Haiku 20240307 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "us-gov-west-1/claude-sonnet-4-5-20250929-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/claude Sonnet 4 5 20250929 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000033,
        "outputCostPerToken": 0.0000165
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us-gov-west-1/meta.llama3-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/meta.llama3 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000265,
        "outputCostPerToken": 0.0000035
      },
      "context": {
        "maxInputTokens": 8000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "pdfInput": true
      }
    },
    "us-gov-west-1/meta.llama3-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us Gov West 1/meta.llama3 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.00000265
      },
      "context": {
        "maxInputTokens": 8000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "pdfInput": true
      }
    },
    "us-west-1/meta.llama3-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us West 1/meta.llama3 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000265,
        "outputCostPerToken": 0.0000035
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "us-west-1/meta.llama3-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us West 1/meta.llama3 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "us-west-2/1-month-commitment/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Us West 2/1 Month Commitment/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/1-month-commitment/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Us West 2/1 Month Commitment/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/1-month-commitment/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Us West 2/1 Month Commitment/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/6-month-commitment/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Us West 2/6 Month Commitment/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/6-month-commitment/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Us West 2/6 Month Commitment/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/6-month-commitment/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Us West 2/6 Month Commitment/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/anthropic.claude-instant-v1": {
      "provider": "bedrock",
      "displayName": "Us West 2/anthropic.claude Instant V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0.0000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/anthropic.claude-v1": {
      "provider": "bedrock",
      "displayName": "Us West 2/anthropic.claude V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/anthropic.claude-v2:1": {
      "provider": "bedrock",
      "displayName": "Us West 2/anthropic.claude V2:1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 100000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/mistral.mistral-7b-instruct-v0:2": {
      "provider": "bedrock",
      "displayName": "Us West 2/mistral.mistral 7b Instruct V0:2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/mistral.mistral-large-2402-v1:0": {
      "provider": "bedrock",
      "displayName": "Us West 2/mistral.mistral Large 2402 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "us-west-2/mistral.mixtral-8x7b-instruct-v0:1": {
      "provider": "bedrock",
      "displayName": "Us West 2/mistral.mixtral 8x7b Instruct V0:1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4.5e-7,
        "outputCostPerToken": 7e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      }
    },
    "us-west-2/moonshotai.kimi-k2-thinking": {
      "provider": "bedrock",
      "displayName": "Us West 2/moonshotai.kimi K2 Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "us.anthropic.claude-3-5-haiku-20241022-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.anthropic.claude 3 5 Haiku 20241022 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0.000004,
        "cacheCreationCostPerToken": 0.000001,
        "cacheReadCostPerToken": 8e-8
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "chat-bison": {
      "provider": "google",
      "displayName": "Chat Bison",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 4096
      }
    },
    "chat-bison-32k": {
      "provider": "google",
      "displayName": "Chat Bison 32k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8192
      }
    },
    "chat-bison-32k@002": {
      "provider": "google",
      "displayName": "Chat Bison 32k@002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8192
      }
    },
    "chat-bison@001": {
      "provider": "google",
      "displayName": "Chat Bison@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 4096
      }
    },
    "chat-bison@002": {
      "provider": "google",
      "displayName": "Chat Bison@002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 4096
      },
      "deprecationDate": "2025-04-09"
    },
    "chatgpt-4o-latest": {
      "provider": "openai",
      "displayName": "OpenAI: ChatGPT-4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true,
        "pdfInput": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "claude-3-5-haiku-20241022": {
      "provider": "anthropic",
      "displayName": "Claude 3.5 Haiku",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0.000004,
        "cacheCreationCostPerToken": 0.000001,
        "cacheReadCostPerToken": 8e-8
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true,
        "webSearch": true
      },
      "deprecationDate": "2025-10-01"
    },
    "claude-3-5-haiku-latest": {
      "provider": "anthropic",
      "displayName": "Claude 3 5 Haiku Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000005,
        "cacheCreationCostPerToken": 0.00000125,
        "cacheReadCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true,
        "webSearch": true
      },
      "deprecationDate": "2025-10-01"
    },
    "claude-haiku-4-5-20251001": {
      "provider": "anthropic",
      "displayName": "Claude Haiku 4 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000005,
        "cacheCreationCostPerToken": 0.00000125,
        "cacheReadCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-haiku-4-5": {
      "provider": "anthropic",
      "displayName": "Claude Haiku 4 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000005,
        "cacheCreationCostPerToken": 0.00000125,
        "cacheReadCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-3-5-sonnet-20240620": {
      "provider": "anthropic",
      "displayName": "Claude 3.5 Sonnet",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "deprecationDate": "2025-06-01"
    },
    "claude-3-5-sonnet-20241022": {
      "provider": "anthropic",
      "displayName": "Claude 3.5 Sonnet",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true,
        "webSearch": true
      },
      "deprecationDate": "2025-10-01"
    },
    "claude-3-5-sonnet-latest": {
      "provider": "anthropic",
      "displayName": "Claude 3 5 Sonnet Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true,
        "webSearch": true
      },
      "deprecationDate": "2025-06-01"
    },
    "claude-3-7-sonnet-20250219": {
      "provider": "anthropic",
      "displayName": "Claude 3.7 Sonnet",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true,
        "webSearch": true
      },
      "deprecationDate": "2026-02-19"
    },
    "claude-3-7-sonnet-latest": {
      "provider": "anthropic",
      "displayName": "Claude 3 7 Sonnet Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "deprecationDate": "2025-06-01"
    },
    "claude-3-haiku-20240307": {
      "provider": "anthropic",
      "displayName": "Claude 3 Haiku",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.00000125,
        "cacheCreationCostPerToken": 3e-7,
        "cacheReadCostPerToken": 3e-8
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      }
    },
    "claude-3-opus-20240229": {
      "provider": "anthropic",
      "displayName": "Claude 3 Opus",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075,
        "cacheCreationCostPerToken": 0.00001875,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      },
      "deprecationDate": "2026-05-01"
    },
    "claude-3-opus-latest": {
      "provider": "anthropic",
      "displayName": "Claude 3 Opus Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075,
        "cacheCreationCostPerToken": 0.00001875,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      },
      "deprecationDate": "2025-03-01"
    },
    "claude-4-opus-20250514": {
      "provider": "anthropic",
      "displayName": "Claude 4 Opus",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075,
        "cacheCreationCostPerToken": 0.00001875,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 32000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-4-sonnet-20250514": {
      "provider": "anthropic",
      "displayName": "Claude 4 Sonnet",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-sonnet-4-5": {
      "provider": "anthropic",
      "displayName": "Claude Sonnet 4 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-sonnet-4-5-20250929": {
      "provider": "anthropic",
      "displayName": "Claude Sonnet 4 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true,
        "webSearch": true
      }
    },
    "claude-sonnet-4-5-20250929-v1:0": {
      "provider": "bedrock",
      "displayName": "Claude Sonnet 4 5 20250929 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-opus-4-1": {
      "provider": "anthropic",
      "displayName": "Claude Opus 4 1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075,
        "cacheCreationCostPerToken": 0.00001875,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 32000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-opus-4-1-20250805": {
      "provider": "anthropic",
      "displayName": "Claude Opus 4 1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075,
        "cacheCreationCostPerToken": 0.00001875,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 32000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "deprecationDate": "2026-08-05"
    },
    "claude-opus-4-20250514": {
      "provider": "anthropic",
      "displayName": "Claude Opus 4",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075,
        "cacheCreationCostPerToken": 0.00001875,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 32000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "deprecationDate": "2026-05-14"
    },
    "claude-opus-4-5-20251101": {
      "provider": "anthropic",
      "displayName": "Claude Opus 4 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025,
        "cacheCreationCostPerToken": 0.00000625,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-opus-4-5": {
      "provider": "anthropic",
      "displayName": "Claude Opus 4 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025,
        "cacheCreationCostPerToken": 0.00000625,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-opus-4-6": {
      "provider": "anthropic",
      "displayName": "Claude Opus 4 6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025,
        "cacheCreationCostPerToken": 0.00000625,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "fast/claude-opus-4-6": {
      "provider": "anthropic",
      "displayName": "Fast/claude Opus 4 6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00003,
        "outputCostPerToken": 0.00015,
        "cacheCreationCostPerToken": 0.00000625,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us/claude-opus-4-6": {
      "provider": "anthropic",
      "displayName": "Us/claude Opus 4 6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000055,
        "outputCostPerToken": 0.0000275,
        "cacheCreationCostPerToken": 0.000006875,
        "cacheReadCostPerToken": 5.5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "fast/us/claude-opus-4-6": {
      "provider": "anthropic",
      "displayName": "Fast/us/claude Opus 4 6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00003,
        "outputCostPerToken": 0.00015,
        "cacheCreationCostPerToken": 0.000006875,
        "cacheReadCostPerToken": 5.5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-opus-4-6-20260205": {
      "provider": "anthropic",
      "displayName": "Claude Opus 4 6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025,
        "cacheCreationCostPerToken": 0.00000625,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "fast/claude-opus-4-6-20260205": {
      "provider": "anthropic",
      "displayName": "Fast/claude Opus 4 6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00003,
        "outputCostPerToken": 0.00015,
        "cacheCreationCostPerToken": 0.00000625,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "us/claude-opus-4-6-20260205": {
      "provider": "anthropic",
      "displayName": "Us/claude Opus 4 6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000055,
        "outputCostPerToken": 0.0000275,
        "cacheCreationCostPerToken": 0.000006875,
        "cacheReadCostPerToken": 5.5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "claude-sonnet-4-20250514": {
      "provider": "anthropic",
      "displayName": "Claude Sonnet 4",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "deprecationDate": "2026-05-14"
    },
    "code-bison": {
      "provider": "google",
      "displayName": "Code Bison",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 6144,
        "maxOutputTokens": 1024
      }
    },
    "code-bison-32k@002": {
      "provider": "google",
      "displayName": "Code Bison 32k@002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 6144,
        "maxOutputTokens": 1024
      }
    },
    "code-bison32k": {
      "provider": "google",
      "displayName": "Code Bison32k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 6144,
        "maxOutputTokens": 1024
      }
    },
    "code-bison@001": {
      "provider": "google",
      "displayName": "Code Bison@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 6144,
        "maxOutputTokens": 1024
      }
    },
    "code-bison@002": {
      "provider": "google",
      "displayName": "Code Bison@002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 6144,
        "maxOutputTokens": 1024
      }
    },
    "code-gecko": {
      "provider": "google",
      "displayName": "Code Gecko",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 2048,
        "maxOutputTokens": 64
      }
    },
    "code-gecko-latest": {
      "provider": "google",
      "displayName": "Code Gecko Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 2048,
        "maxOutputTokens": 64
      }
    },
    "code-gecko@001": {
      "provider": "google",
      "displayName": "Code Gecko@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 2048,
        "maxOutputTokens": 64
      }
    },
    "code-gecko@002": {
      "provider": "google",
      "displayName": "Code Gecko@002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 2048,
        "maxOutputTokens": 64
      }
    },
    "codechat-bison": {
      "provider": "google",
      "displayName": "Codechat Bison",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 6144,
        "maxOutputTokens": 1024
      }
    },
    "codechat-bison-32k": {
      "provider": "google",
      "displayName": "Codechat Bison 32k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8192
      }
    },
    "codechat-bison-32k@002": {
      "provider": "google",
      "displayName": "Codechat Bison 32k@002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8192
      }
    },
    "codechat-bison@001": {
      "provider": "google",
      "displayName": "Codechat Bison@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 6144,
        "maxOutputTokens": 1024
      }
    },
    "codechat-bison@002": {
      "provider": "google",
      "displayName": "Codechat Bison@002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 6144,
        "maxOutputTokens": 1024
      }
    },
    "codechat-bison@latest": {
      "provider": "google",
      "displayName": "Codechat Bison@latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 6144,
        "maxOutputTokens": 1024
      }
    },
    "codex-mini-latest": {
      "provider": "openai",
      "displayName": "Codex Mini Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000015,
        "outputCostPerToken": 0.000006,
        "cacheReadCostPerToken": 3.75e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "cohere.command-light-text-v14": {
      "provider": "bedrock",
      "displayName": "Cohere.command Light Text V14",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "cohere.command-r-plus-v1:0": {
      "provider": "bedrock",
      "displayName": "Cohere.command R Plus V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      }
    },
    "cohere.command-r-v1:0": {
      "provider": "bedrock",
      "displayName": "Cohere.command R V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      }
    },
    "cohere.command-text-v14": {
      "provider": "bedrock",
      "displayName": "Cohere.command Text V14",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000015,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "cohere.embed-english-v3": {
      "provider": "bedrock",
      "displayName": "Cohere.embed English V3",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 512
      }
    },
    "cohere.embed-multilingual-v3": {
      "provider": "bedrock",
      "displayName": "Cohere.embed Multilingual V3",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 512
      }
    },
    "cohere.embed-v4:0": {
      "provider": "bedrock",
      "displayName": "Cohere.embed V4:0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.2e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 128000
      }
    },
    "embed-v4.0": {
      "provider": "cohere",
      "displayName": "Embed V4.0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.2e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 128000
      }
    },
    "cohere.rerank-v3-5:0": {
      "provider": "bedrock",
      "displayName": "Cohere.rerank V3 5:0",
      "mode": "rerank",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 32000
      }
    },
    "command": {
      "provider": "cohere",
      "displayName": "Command",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "command-nightly": {
      "provider": "cohere",
      "displayName": "Command Nightly",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "dall-e-2": {
      "provider": "openai",
      "displayName": "DALL-E 2",
      "mode": "image_generation",
      "source": "litellm"
    },
    "dall-e-3": {
      "provider": "openai",
      "displayName": "DALL-E 3",
      "mode": "image_generation",
      "source": "litellm"
    },
    "deepseek-chat": {
      "provider": "deepseek",
      "displayName": "DeepSeek: DeepSeek V3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.8e-7,
        "outputCostPerToken": 4.2e-7,
        "cacheReadCostPerToken": 2.8e-8
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ]
    },
    "deepseek-reasoner": {
      "provider": "deepseek",
      "displayName": "Deepseek Reasoner",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.8e-7,
        "outputCostPerToken": 4.2e-7,
        "cacheReadCostPerToken": 2.8e-8
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "functionCalling": false,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true
      }
    },
    "deepseek-coder": {
      "provider": "deepseek",
      "displayName": "Deepseek Coder",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.4e-7,
        "outputCostPerToken": 2.8e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true
      }
    },
    "deepseek-r1": {
      "provider": "deepseek",
      "displayName": "DeepSeek: R1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.5e-7,
        "outputCostPerToken": 0.00000219
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true,
        "reasoning": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ]
    },
    "deepseek-v3": {
      "provider": "deepseek",
      "displayName": "Deepseek V3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.7e-7,
        "outputCostPerToken": 0.0000011,
        "cacheCreationCostPerToken": 0,
        "cacheReadCostPerToken": 7e-8
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true
      }
    },
    "deepseek-v3.2": {
      "provider": "deepseek",
      "displayName": "DeepSeek: DeepSeek V3.2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.8e-7,
        "outputCostPerToken": 4e-7
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 163840
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true,
        "reasoning": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ]
    },
    "search": {
      "provider": "perplexity",
      "displayName": "Search",
      "mode": "chat",
      "source": "litellm"
    },
    "embed-english-light-v2.0": {
      "provider": "cohere",
      "displayName": "Embed English Light V2.0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 1024
      }
    },
    "embed-english-light-v3.0": {
      "provider": "cohere",
      "displayName": "Embed English Light V3.0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 1024
      }
    },
    "embed-english-v2.0": {
      "provider": "cohere",
      "displayName": "Embed English V2.0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 4096
      }
    },
    "embed-english-v3.0": {
      "provider": "cohere",
      "displayName": "Embed English V3.0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 1024
      }
    },
    "embed-multilingual-v2.0": {
      "provider": "cohere",
      "displayName": "Embed Multilingual V2.0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 768
      }
    },
    "embed-multilingual-v3.0": {
      "provider": "cohere",
      "displayName": "Embed Multilingual V3.0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 1024
      }
    },
    "embed-multilingual-light-v3.0": {
      "provider": "cohere",
      "displayName": "Embed Multilingual Light V3.0",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0001,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 1024
      }
    },
    "eu.anthropic.claude-3-5-haiku-20241022-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu.anthropic.claude 3 5 Haiku 20241022 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu.anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "eu.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "provider": "bedrock",
      "displayName": "Eu.anthropic.claude 3 5 Sonnet 20241022 V2:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "eu.anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu.anthropic.claude 3 7 Sonnet 20250219 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "eu.anthropic.claude-3-haiku-20240307-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu.anthropic.claude 3 Haiku 20240307 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "eu.anthropic.claude-3-opus-20240229-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu.anthropic.claude 3 Opus 20240229 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "eu.anthropic.claude-3-sonnet-20240229-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu.anthropic.claude 3 Sonnet 20240229 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "eu.meta.llama3-2-1b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu.meta.llama3 2 1b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.3e-7,
        "outputCostPerToken": 1.3e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "eu.meta.llama3-2-3b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Eu.meta.llama3 2 3b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.9e-7,
        "outputCostPerToken": 1.9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "fireworks-ai-4.1b-to-16b": {
      "provider": "fireworks_ai",
      "displayName": "Fireworks Ai 4.1b To 16b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      }
    },
    "fireworks-ai-56b-to-176b": {
      "provider": "fireworks_ai",
      "displayName": "Fireworks Ai 56b To 176b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      }
    },
    "fireworks-ai-above-16b": {
      "provider": "fireworks_ai",
      "displayName": "Fireworks Ai Above 16b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      }
    },
    "fireworks-ai-default": {
      "provider": "fireworks_ai",
      "displayName": "Fireworks Ai Default",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      }
    },
    "fireworks-ai-moe-up-to-56b": {
      "provider": "fireworks_ai",
      "displayName": "Fireworks Ai Moe Up To 56b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      }
    },
    "fireworks-ai-up-to-4b": {
      "provider": "fireworks_ai",
      "displayName": "Fireworks Ai Up To 4b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      }
    },
    "accounts/fireworks/models/deepseek-coder-v2-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek Coder V2 Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "functionCalling": false,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/deepseek-r1": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek R1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000008
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 20480
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/deepseek-r1-0528": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek R1 0528",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000008
      },
      "context": {
        "maxInputTokens": 160000,
        "maxOutputTokens": 160000
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/deepseek-r1-basic": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek R1 Basic",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.5e-7,
        "outputCostPerToken": 0.00000219
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 20480
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/deepseek-v3": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek V3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/deepseek-v3-0324": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek V3 0324",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 163840
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/deepseek-v3p1": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek V3p1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.6e-7,
        "outputCostPerToken": 0.00000168
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "accounts/fireworks/models/deepseek-v3p1-terminus": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek V3p1 Terminus",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.6e-7,
        "outputCostPerToken": 0.00000168
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "accounts/fireworks/models/deepseek-v3p2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek V3p2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.6e-7,
        "outputCostPerToken": 0.00000168
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 163840
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "accounts/fireworks/models/firefunction-v2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/firefunction V2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/glm-4p5": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/glm 4p5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.5e-7,
        "outputCostPerToken": 0.00000219
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 96000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "accounts/fireworks/models/glm-4p5-air": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/glm 4p5 Air",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.2e-7,
        "outputCostPerToken": 8.8e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 96000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "accounts/fireworks/models/glm-4p6": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/glm 4p6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.5e-7,
        "outputCostPerToken": 0.00000219
      },
      "context": {
        "maxInputTokens": 202800,
        "maxOutputTokens": 202800
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "accounts/fireworks/models/gpt-oss-120b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/gpt Oss 120b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "accounts/fireworks/models/gpt-oss-20b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/gpt Oss 20b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-8,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "accounts/fireworks/models/kimi-k2-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/kimi K2 Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/kimi-k2-instruct-0905": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/kimi K2 Instruct 0905",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/kimi-k2-thinking": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/kimi K2 Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "webSearch": true
      }
    },
    "accounts/fireworks/models/llama-v3p1-405b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p1 405b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/llama-v3p1-8b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p1 8b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": false,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p2 11b Vision Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": false,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/llama-v3p2-1b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p2 1b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": false,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/llama-v3p2-3b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p2 3b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": false,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p2 90b Vision Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/llama4-maverick-instruct-basic": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama4 Maverick Instruct Basic",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.2e-7,
        "outputCostPerToken": 8.8e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/llama4-scout-instruct-basic": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama4 Scout Instruct Basic",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/mixtral-8x22b-instruct-hf": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mixtral 8x22b Instruct Hf",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/qwen2-72b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2 72b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": false,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 32b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": false,
        "structuredOutput": true
      }
    },
    "accounts/fireworks/models/yi-large": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/yi Large",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000003
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": false,
        "structuredOutput": true
      }
    },
    "ft:gpt-3.5-turbo": {
      "provider": "openai",
      "displayName": "Ft:gpt 3.5 Turbo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 16385,
        "maxOutputTokens": 4096
      }
    },
    "ft:gpt-3.5-turbo-0125": {
      "provider": "openai",
      "displayName": "Ft:gpt 3.5 Turbo 0125",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 16385,
        "maxOutputTokens": 4096
      }
    },
    "ft:gpt-3.5-turbo-0613": {
      "provider": "openai",
      "displayName": "Ft:gpt 3.5 Turbo 0613",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "ft:gpt-3.5-turbo-1106": {
      "provider": "openai",
      "displayName": "Ft:gpt 3.5 Turbo 1106",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 16385,
        "maxOutputTokens": 4096
      }
    },
    "ft:gpt-4-0613": {
      "provider": "openai",
      "displayName": "Ft:gpt 4 0613",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00003,
        "outputCostPerToken": 0.00006
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "ft:gpt-4o-2024-08-06": {
      "provider": "openai",
      "displayName": "Ft:gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000375,
        "outputCostPerToken": 0.000015,
        "cacheReadCostPerToken": 0.000001875
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "ft:gpt-4o-2024-11-20": {
      "provider": "openai",
      "displayName": "Ft:gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000375,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.000001875
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "ft:gpt-4o-mini-2024-07-18": {
      "provider": "openai",
      "displayName": "Ft:gpt 4o Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000012,
        "cacheReadCostPerToken": 1.5e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "ft:gpt-4.1-2025-04-14": {
      "provider": "openai",
      "displayName": "Ft:gpt 4.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000012,
        "cacheReadCostPerToken": 7.5e-7
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      }
    },
    "ft:gpt-4.1-mini-2025-04-14": {
      "provider": "openai",
      "displayName": "Ft:gpt 4.1 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0.0000032,
        "cacheReadCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      }
    },
    "ft:gpt-4.1-nano-2025-04-14": {
      "provider": "openai",
      "displayName": "Ft:gpt 4.1 Nano",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 8e-7,
        "cacheReadCostPerToken": 5e-8
      },
      "context": {
        "maxInputTokens": 1047576,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true
      }
    },
    "ft:o4-mini-2025-04-16": {
      "provider": "openai",
      "displayName": "Ft:o4 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000004,
        "outputCostPerToken": 0.000016,
        "cacheReadCostPerToken": 0.000001
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true
      }
    },
    "gemini-1.0-pro": {
      "provider": "google",
      "displayName": "Gemini 1.0 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 32760,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      }
    },
    "gemini-1.0-pro-001": {
      "provider": "google",
      "displayName": "Gemini 1.0 Pro 001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 32760,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      },
      "deprecationDate": "2025-04-09"
    },
    "gemini-1.0-pro-002": {
      "provider": "google",
      "displayName": "Gemini 1.0 Pro 002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 32760,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      },
      "deprecationDate": "2025-04-09"
    },
    "gemini-1.0-pro-vision": {
      "provider": "google",
      "displayName": "Gemini 1.0 Pro Vision",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true
      }
    },
    "gemini-1.0-pro-vision-001": {
      "provider": "google",
      "displayName": "Gemini 1.0 Pro Vision 001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true
      },
      "deprecationDate": "2025-04-09"
    },
    "gemini-1.0-ultra": {
      "provider": "google",
      "displayName": "Gemini 1.0 Ultra",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      }
    },
    "gemini-1.0-ultra-001": {
      "provider": "google",
      "displayName": "Gemini 1.0 Ultra 001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      }
    },
    "gemini-1.5-flash": {
      "provider": "google",
      "displayName": "Gemini 1.5 Flash",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.5e-8,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2025-09-29"
    },
    "gemini-1.5-flash-001": {
      "provider": "google",
      "displayName": "Gemini 1.5 Flash 001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.5e-8,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2025-05-24"
    },
    "gemini-1.5-flash-002": {
      "provider": "google",
      "displayName": "Gemini 1.5 Flash 002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.5e-8,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2025-09-24"
    },
    "gemini-1.5-flash-exp-0827": {
      "provider": "google",
      "displayName": "Gemini 1.5 Flash",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4.688e-9,
        "outputCostPerToken": 4.6875e-9
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2025-09-29"
    },
    "gemini-1.5-flash-preview-0514": {
      "provider": "google",
      "displayName": "Gemini 1.5 Flash",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.5e-8,
        "outputCostPerToken": 4.6875e-9
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true
      },
      "deprecationDate": "2025-09-29"
    },
    "gemini-1.5-pro": {
      "provider": "google",
      "displayName": "Gemini 1.5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 2097152,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      },
      "deprecationDate": "2025-09-29"
    },
    "gemini-1.5-pro-001": {
      "provider": "google",
      "displayName": "Gemini 1.5 Pro 001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2025-05-24"
    },
    "gemini-1.5-pro-002": {
      "provider": "google",
      "displayName": "Gemini 1.5 Pro 002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 2097152,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2025-09-24"
    },
    "gemini-1.5-pro-preview-0215": {
      "provider": "google",
      "displayName": "Gemini 1.5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.8125e-8,
        "outputCostPerToken": 3.125e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2025-09-29"
    },
    "gemini-1.5-pro-preview-0409": {
      "provider": "google",
      "displayName": "Gemini 1.5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.8125e-8,
        "outputCostPerToken": 3.125e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2025-09-29"
    },
    "gemini-1.5-pro-preview-0514": {
      "provider": "google",
      "displayName": "Gemini 1.5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.8125e-8,
        "outputCostPerToken": 3.125e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      },
      "deprecationDate": "2025-09-29"
    },
    "gemini-2.0-flash": {
      "provider": "google",
      "displayName": "Gemini 2.0 Flash",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 4e-7,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioInput": true,
        "audioOutput": true,
        "webSearch": true
      },
      "deprecationDate": "2026-03-31"
    },
    "gemini-2.0-flash-001": {
      "provider": "google",
      "displayName": "Google: Gemini 2.0 Flash",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7,
        "cacheReadCostPerToken": 3.75e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioOutput": true,
        "webSearch": true,
        "audioInput": true
      },
      "deprecationDate": "2026-03-31",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-2.0-flash-exp": {
      "provider": "google",
      "displayName": "Gemini 2.0 Flash",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7,
        "cacheReadCostPerToken": 3.75e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioOutput": true,
        "webSearch": true
      }
    },
    "gemini-2.0-flash-lite": {
      "provider": "google",
      "displayName": "Gemini 2.0 Flash Lite",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.5e-8,
        "outputCostPerToken": 3e-7,
        "cacheReadCostPerToken": 1.875e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioOutput": true,
        "webSearch": true
      },
      "deprecationDate": "2026-03-31"
    },
    "gemini-2.0-flash-lite-001": {
      "provider": "google",
      "displayName": "Google: Gemini 2.0 Flash Lite",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.5e-8,
        "outputCostPerToken": 3e-7,
        "cacheReadCostPerToken": 1.875e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioOutput": true,
        "webSearch": true,
        "audioInput": true
      },
      "deprecationDate": "2026-03-31",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-2.0-flash-live-preview-04-09": {
      "provider": "google",
      "displayName": "Gemini 2.0 Flash Live Preview 04 09",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.000002,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": true,
        "pdfInput": true,
        "webSearch": true
      }
    },
    "gemini-2.0-flash-preview-image-generation": {
      "provider": "google",
      "displayName": "Gemini 2.0 Flash",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 4e-7,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioInput": true,
        "audioOutput": true,
        "webSearch": true
      },
      "deprecationDate": "2025-11-14"
    },
    "gemini-2.0-flash-thinking-exp": {
      "provider": "google",
      "displayName": "Gemini 2.0 Flash Thinking Exp",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0,
        "cacheReadCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioOutput": true,
        "webSearch": true
      },
      "deprecationDate": "2025-12-02"
    },
    "gemini-2.0-flash-thinking-exp-01-21": {
      "provider": "google",
      "displayName": "Gemini 2.0 Flash Thinking Exp 01 21",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0,
        "cacheReadCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "vision": true,
        "functionCalling": false,
        "parallelFunctionCalling": true,
        "structuredOutput": false,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "webSearch": true
      },
      "deprecationDate": "2025-12-02"
    },
    "gemini-2.0-pro-exp-02-05": {
      "provider": "google",
      "displayName": "Gemini 2.0 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 3.125e-7
      },
      "context": {
        "maxInputTokens": 2097152,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioInput": true,
        "pdfInput": true,
        "webSearch": true
      }
    },
    "gemini-2.5-flash": {
      "provider": "google",
      "displayName": "Google: Gemini 2.5 Flash",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000025,
        "cacheReadCostPerToken": 3e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true,
        "audioInput": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-2.5-flash-image": {
      "provider": "google",
      "displayName": "Google: Gemini 2.5 Flash Image (Nano Banana)",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000025,
        "cacheReadCostPerToken": 3e-8
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": false
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-2.5-flash-image-preview": {
      "provider": "google",
      "displayName": "Gemini 2.5 Flash Image Preview",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.00003,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true
      },
      "deprecationDate": "2026-01-15"
    },
    "gemini-3-pro-image-preview": {
      "provider": "google",
      "displayName": "Google: Nano Banana Pro (Gemini 3 Pro Image Preview)",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000012
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "webSearch": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "deep-research-pro-preview-12-2025": {
      "provider": "google",
      "displayName": "Deep Research Pro Preview 12 2025",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000012
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "webSearch": true
      }
    },
    "gemini-2.5-flash-lite": {
      "provider": "google",
      "displayName": "Google: Gemini 2.5 Flash Lite",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 4e-7,
        "cacheReadCostPerToken": 1e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true,
        "audioInput": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-2.5-flash-lite-preview-09-2025": {
      "provider": "google",
      "displayName": "Google: Gemini 2.5 Flash Lite Preview 09-2025",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 4e-7,
        "cacheReadCostPerToken": 1e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true,
        "audioInput": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-2.5-flash-preview-09-2025": {
      "provider": "google",
      "displayName": "Google: Gemini 2.5 Flash Preview 09-2025",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000025,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true,
        "audioInput": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-live-2.5-flash-preview-native-audio-09-2025": {
      "provider": "google",
      "displayName": "Gemini Live 2.5 Flash Preview Native Audio 09 2025",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.000002,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioInput": true,
        "audioOutput": true,
        "pdfInput": true,
        "webSearch": true
      }
    },
    "gemini-2.5-flash-lite-preview-06-17": {
      "provider": "google",
      "displayName": "Gemini 2.5 Flash Lite Preview 06 17",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 4e-7,
        "cacheReadCostPerToken": 2.5e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true
      },
      "deprecationDate": "2025-11-18"
    },
    "gemini-2.5-flash-preview-04-17": {
      "provider": "google",
      "displayName": "Gemini 2.5 Flash",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7,
        "cacheReadCostPerToken": 3.75e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true
      }
    },
    "gemini-2.5-flash-preview-05-20": {
      "provider": "google",
      "displayName": "Gemini 2.5 Flash",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000025,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true
      },
      "deprecationDate": "2025-11-18"
    },
    "gemini-2.5-pro": {
      "provider": "google",
      "displayName": "Google: Gemini 2.5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioInput": true,
        "pdfInput": true,
        "webSearch": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-3-pro-preview": {
      "provider": "google",
      "displayName": "Google: Gemini 3 Pro Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000012,
        "cacheReadCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioInput": true,
        "pdfInput": true,
        "webSearch": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-3-flash-preview": {
      "provider": "google",
      "displayName": "Google: Gemini 3 Flash Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.000003,
        "cacheReadCostPerToken": 5e-8
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true,
        "audioInput": true
      },
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-2.5-pro-exp-03-25": {
      "provider": "google",
      "displayName": "Gemini 2.5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioInput": true,
        "pdfInput": true,
        "webSearch": true
      }
    },
    "gemini-2.5-pro-preview-03-25": {
      "provider": "google",
      "displayName": "Gemini 2.5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true
      },
      "deprecationDate": "2025-12-02"
    },
    "gemini-2.5-pro-preview-05-06": {
      "provider": "google",
      "displayName": "Google: Gemini 2.5 Pro Preview 05-06",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true,
        "audioInput": true
      },
      "deprecationDate": "2025-12-02",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ]
    },
    "gemini-2.5-pro-preview-06-05": {
      "provider": "google",
      "displayName": "Gemini 2.5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true
      }
    },
    "gemini-2.5-pro-preview-tts": {
      "provider": "google",
      "displayName": "Gemini 2.5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioOutput": false,
        "webSearch": true
      }
    },
    "gemini-robotics-er-1.5-preview": {
      "provider": "google",
      "displayName": "Gemini Robotics Er 1.5 Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000025,
        "cacheReadCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65535
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": false,
        "reasoning": true,
        "audioOutput": false
      }
    },
    "gemini-2.5-computer-use-preview-10-2025": {
      "provider": "google",
      "displayName": "Gemini 2.5 Computer Use Preview 10 2025",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "gemini-embedding-001": {
      "provider": "google",
      "displayName": "Gemini Embedding 001",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 2048
      }
    },
    "gemini-flash-experimental": {
      "provider": "google",
      "displayName": "Gemini Flash Experimental",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": false,
        "parallelFunctionCalling": true
      }
    },
    "gemini-pro": {
      "provider": "google",
      "displayName": "Gemini Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 32760,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      }
    },
    "gemini-pro-experimental": {
      "provider": "google",
      "displayName": "Gemini Pro Experimental",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": false,
        "parallelFunctionCalling": true
      }
    },
    "gemini-pro-vision": {
      "provider": "google",
      "displayName": "Gemini Pro Vision",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true
      }
    },
    "gemini/gemini-2.5-flash-image": {
      "provider": "google",
      "displayName": "Gemini/gemini 2.5 Flash Image",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000025,
        "cacheReadCostPerToken": 3e-8
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": false,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": true
      }
    },
    "gpt-3.5-turbo-0301": {
      "provider": "openai",
      "displayName": "Gpt 3.5 Turbo 0301",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000015,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 4097,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "promptCaching": true
      }
    },
    "gpt-3.5-turbo-0613": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-3.5 Turbo (older v0613)",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000015,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 4097,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-3.5-turbo-1106": {
      "provider": "openai",
      "displayName": "Gpt 3.5 Turbo 1106",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 16385,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true
      },
      "deprecationDate": "2026-09-28"
    },
    "gpt-3.5-turbo-16k": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-3.5 Turbo 16k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000004
      },
      "context": {
        "maxInputTokens": 16385,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "promptCaching": true,
        "functionCalling": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-3.5-turbo-16k-0613": {
      "provider": "openai",
      "displayName": "Gpt 3.5 Turbo 16k 0613",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000004
      },
      "context": {
        "maxInputTokens": 16385,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "promptCaching": true
      }
    },
    "gpt-4-0314": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4 (older v0314)",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00003,
        "outputCostPerToken": 0.00006
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "promptCaching": true,
        "functionCalling": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4-1106-vision-preview": {
      "provider": "openai",
      "displayName": "Gpt 4 1106 Vision Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "deprecationDate": "2024-12-06"
    },
    "gpt-4-32k-0314": {
      "provider": "openai",
      "displayName": "Gpt 4 32k 0314",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00006,
        "outputCostPerToken": 0.00012
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "promptCaching": true
      }
    },
    "gpt-4-turbo-preview": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4 Turbo Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "promptCaching": true,
        "pdfInput": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4-vision-preview": {
      "provider": "openai",
      "displayName": "Gpt 4 Vision Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "deprecationDate": "2024-12-06"
    },
    "gpt-4.5-preview-2025-02-27": {
      "provider": "openai",
      "displayName": "Gpt 4.5 Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000075,
        "outputCostPerToken": 0.00015,
        "cacheReadCostPerToken": 0.0000375
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "deprecationDate": "2025-07-14"
    },
    "gpt-4o-audio-preview": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4o Audio",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true,
        "structuredOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-4o-audio-preview-2024-10-01": {
      "provider": "openai",
      "displayName": "Gpt 4o Audio Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-audio-preview-2025-06-03": {
      "provider": "openai",
      "displayName": "Gpt 4o Audio Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-audio": {
      "provider": "openai",
      "displayName": "OpenAI: GPT Audio",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": false,
        "promptCaching": false,
        "reasoning": false,
        "audioInput": true,
        "audioOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-audio-mini": {
      "provider": "openai",
      "displayName": "OpenAI: GPT Audio Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000024
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": false,
        "promptCaching": false,
        "reasoning": false,
        "audioInput": true,
        "audioOutput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "gpt-audio-mini-2025-12-15": {
      "provider": "openai",
      "displayName": "Gpt Audio Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000024
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": false,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": false,
        "promptCaching": false,
        "reasoning": false,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-mini-audio-preview": {
      "provider": "openai",
      "displayName": "Gpt 4o Mini Audio Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-mini-realtime-preview": {
      "provider": "openai",
      "displayName": "Gpt 4o Mini Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000024,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-mini-search-preview": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4o-mini Search Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true,
        "webSearch": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-4o-mini-search-preview-2025-03-11": {
      "provider": "openai",
      "displayName": "Gpt 4o Mini Search Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "gpt-4o-realtime-preview": {
      "provider": "openai",
      "displayName": "Gpt 4o Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.00002,
        "cacheReadCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-realtime-preview-2025-06-03": {
      "provider": "openai",
      "displayName": "Gpt 4o Realtime Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.00002,
        "cacheReadCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-4o-search-preview": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4o Search Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true,
        "webSearch": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "gpt-4o-search-preview-2025-03-11": {
      "provider": "openai",
      "displayName": "Gpt 4o Search Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "low/1024-x-1024/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "Low/1024 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "low/1024-x-1536/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "Low/1024 X 1536/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "low/1536-x-1024/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "Low/1536 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "medium/1024-x-1024/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "Medium/1024 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "medium/1024-x-1536/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "Medium/1024 X 1536/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "medium/1536-x-1024/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "Medium/1536 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "high/1024-x-1024/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "High/1024 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "high/1024-x-1536/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "High/1024 X 1536/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "high/1536-x-1024/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "High/1536 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "standard/1024-x-1024/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "Standard/1024 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "standard/1024-x-1536/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "Standard/1024 X 1536/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "standard/1536-x-1024/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "Standard/1536 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "1024-x-1024/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "1024 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "1024-x-1536/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "1024 X 1536/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "1536-x-1024/gpt-image-1.5": {
      "provider": "openai",
      "displayName": "1536 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "low/1024-x-1024/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "Low/1024 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "low/1024-x-1536/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "Low/1024 X 1536/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "low/1536-x-1024/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "Low/1536 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "medium/1024-x-1024/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "Medium/1024 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "medium/1024-x-1536/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "Medium/1024 X 1536/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "medium/1536-x-1024/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "Medium/1536 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "high/1024-x-1024/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "High/1024 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "high/1024-x-1536/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "High/1024 X 1536/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "high/1536-x-1024/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "High/1536 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "standard/1024-x-1024/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "Standard/1024 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "standard/1024-x-1536/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "Standard/1024 X 1536/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "standard/1536-x-1024/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "Standard/1536 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "1024-x-1024/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "1024 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "1024-x-1536/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "1024 X 1536/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "1536-x-1024/gpt-image-1.5-2025-12-16": {
      "provider": "openai",
      "displayName": "1536 X 1024/gpt Image 1.5",
      "mode": "image_generation",
      "source": "litellm",
      "capabilities": {
        "vision": true,
        "pdfInput": true
      }
    },
    "gpt-5.1-chat-latest": {
      "provider": "openai",
      "displayName": "Gpt 5.1 Chat Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001,
        "cacheReadCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": false,
        "parallelFunctionCalling": false,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5.2-chat-latest": {
      "provider": "openai",
      "displayName": "Gpt 5.2 Chat Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000175,
        "outputCostPerToken": 0.000014,
        "cacheReadCostPerToken": 1.75e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "gpt-5-pro-2025-10-06": {
      "provider": "openai",
      "displayName": "Gpt 5 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.00012
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true,
        "webSearch": true
      }
    },
    "gpt-realtime": {
      "provider": "openai",
      "displayName": "Gpt Realtime",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000004,
        "outputCostPerToken": 0.000016,
        "cacheReadCostPerToken": 4e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "gpt-realtime-mini": {
      "provider": "openai",
      "displayName": "Gpt Realtime Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000024
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "audioInput": true,
        "audioOutput": true
      }
    },
    "llama-3.1-8b-instant": {
      "provider": "groq",
      "displayName": "Llama 3.1 8b Instant",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-8,
        "outputCostPerToken": 8e-8
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false
      }
    },
    "llama-3.3-70b-versatile": {
      "provider": "groq",
      "displayName": "Llama 3.3 70b Versatile",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.9e-7,
        "outputCostPerToken": 7.9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false
      }
    },
    "gemma-7b-it": {
      "provider": "groq",
      "displayName": "Gemma 7b It",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-8,
        "outputCostPerToken": 8e-8
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false
      }
    },
    "meta-llama/llama-guard-4-12b": {
      "provider": "groq",
      "displayName": "Meta Llama/llama Guard 4 12b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "meta-llama/llama-4-maverick-17b-128e-instruct": {
      "provider": "groq",
      "displayName": "Meta Llama/llama 4 Maverick 17b 128e Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "meta-llama/llama-4-scout-17b-16e-instruct": {
      "provider": "groq",
      "displayName": "Meta Llama/llama 4 Scout 17b 16e Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.1e-7,
        "outputCostPerToken": 3.4e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "moonshotai/kimi-k2-instruct-0905": {
      "provider": "groq",
      "displayName": "Moonshotai/kimi K2 Instruct 0905",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000003,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "openai/gpt-oss-120b": {
      "provider": "groq",
      "displayName": "Openai/gpt Oss 120b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 32766
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "reasoning": true,
        "webSearch": true
      }
    },
    "openai/gpt-oss-20b": {
      "provider": "groq",
      "displayName": "Openai/gpt Oss 20b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.5e-8,
        "outputCostPerToken": 3e-7,
        "cacheReadCostPerToken": 3.75e-8
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "reasoning": true,
        "webSearch": true
      }
    },
    "playai-tts": {
      "provider": "groq",
      "displayName": "Playai Tts",
      "mode": "audio_speech",
      "source": "litellm",
      "context": {
        "maxInputTokens": 10000,
        "maxOutputTokens": 10000
      }
    },
    "qwen/qwen3-32b": {
      "provider": "groq",
      "displayName": "Qwen/qwen3 32b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.9e-7,
        "outputCostPerToken": 5.9e-7
      },
      "context": {
        "maxInputTokens": 131000,
        "maxOutputTokens": 131000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "reasoning": true
      }
    },
    "whisper-large-v3": {
      "provider": "groq",
      "displayName": "Whisper Large V3",
      "mode": "audio_transcription",
      "source": "litellm"
    },
    "whisper-large-v3-turbo": {
      "provider": "groq",
      "displayName": "Whisper Large V3 Turbo",
      "mode": "audio_transcription",
      "source": "litellm"
    },
    "max-x-max/50-steps/stability.stable-diffusion-xl-v0": {
      "provider": "bedrock",
      "displayName": "Max X Max/50 Steps/stability.stable Diffusion Xl V0",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "max-x-max/max-steps/stability.stable-diffusion-xl-v0": {
      "provider": "bedrock",
      "displayName": "Max X Max/max Steps/stability.stable Diffusion Xl V0",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "medlm-large": {
      "provider": "google",
      "displayName": "Medlm Large",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 1024
      }
    },
    "medlm-medium": {
      "provider": "google",
      "displayName": "Medlm Medium",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 8192
      }
    },
    "meta.llama2-13b-chat-v1": {
      "provider": "bedrock",
      "displayName": "Meta.llama2 13b Chat V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.5e-7,
        "outputCostPerToken": 0.000001
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "meta.llama2-70b-chat-v1": {
      "provider": "bedrock",
      "displayName": "Meta.llama2 70b Chat V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000195,
        "outputCostPerToken": 0.00000256
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "meta.llama3-1-405b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Meta.llama3 1 405b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000532,
        "outputCostPerToken": 0.000016
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "meta.llama3-1-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Meta.llama3 1 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9.9e-7,
        "outputCostPerToken": 9.9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "meta.llama3-1-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Meta.llama3 1 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.2e-7,
        "outputCostPerToken": 2.2e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "meta.llama3-2-11b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Meta.llama3 2 11b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3.5e-7,
        "outputCostPerToken": 3.5e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "meta.llama3-2-1b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Meta.llama3 2 1b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "meta.llama3-2-3b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Meta.llama3 2 3b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 1.5e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "meta.llama3-2-90b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Meta.llama3 2 90b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "meta.llama3-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Meta.llama3 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000265,
        "outputCostPerToken": 0.0000035
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "meta.llama3-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Meta.llama3 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "mistral.mistral-7b-instruct-v0:2": {
      "provider": "bedrock",
      "displayName": "Mistral.mistral 7b Instruct V0:2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      }
    },
    "mistral.mistral-large-2402-v1:0": {
      "provider": "bedrock",
      "displayName": "Mistral.mistral Large 2402 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000008,
        "outputCostPerToken": 0.000024
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "mistral.mistral-large-2407-v1:0": {
      "provider": "bedrock",
      "displayName": "Mistral.mistral Large 2407 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000009
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "mistral.mistral-small-2402-v1:0": {
      "provider": "bedrock",
      "displayName": "Mistral.mistral Small 2402 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000003
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "mistral.mixtral-8x7b-instruct-v0:1": {
      "provider": "bedrock",
      "displayName": "Mistral.mixtral 8x7b Instruct V0:1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4.5e-7,
        "outputCostPerToken": 7e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      }
    },
    "codestral-2405": {
      "provider": "mistral",
      "displayName": "Codestral 2405",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000003
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "codestral-2508": {
      "provider": "mistral",
      "displayName": "Codestral 2508",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "codestral-latest": {
      "provider": "mistral",
      "displayName": "Codestral Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000003
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "codestral-mamba-latest": {
      "provider": "mistral",
      "displayName": "Codestral Mamba Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 2.5e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "devstral-medium-2507": {
      "provider": "mistral",
      "displayName": "Devstral Medium 2507",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "devstral-small-2505": {
      "provider": "mistral",
      "displayName": "Devstral Small 2505",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "devstral-small-2507": {
      "provider": "mistral",
      "displayName": "Devstral Small 2507",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "labs-devstral-small-2512": {
      "provider": "mistral",
      "displayName": "Labs Devstral Small 2512",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "devstral-2512": {
      "provider": "mistral",
      "displayName": "Devstral 2512",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "magistral-medium-2506": {
      "provider": "mistral",
      "displayName": "Magistral Medium 2506",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 40000,
        "maxOutputTokens": 40000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "magistral-medium-2509": {
      "provider": "mistral",
      "displayName": "Magistral Medium 2509",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 40000,
        "maxOutputTokens": 40000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "mistral-ocr-latest": {
      "provider": "mistral",
      "displayName": "Mistral Ocr Latest",
      "mode": "chat",
      "source": "litellm"
    },
    "mistral-ocr-2505-completion": {
      "provider": "mistral",
      "displayName": "Mistral Ocr 2505 Completion",
      "mode": "chat",
      "source": "litellm"
    },
    "magistral-medium-latest": {
      "provider": "mistral",
      "displayName": "Magistral Medium Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 40000,
        "maxOutputTokens": 40000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "magistral-small-2506": {
      "provider": "mistral",
      "displayName": "Magistral Small 2506",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 40000,
        "maxOutputTokens": 40000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "magistral-small-latest": {
      "provider": "mistral",
      "displayName": "Magistral Small Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 40000,
        "maxOutputTokens": 40000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true
      }
    },
    "mistral-embed": {
      "provider": "mistral",
      "displayName": "Mistral Embed",
      "mode": "embedding",
      "source": "litellm",
      "context": {
        "maxInputTokens": 8192
      }
    },
    "codestral-embed": {
      "provider": "mistral",
      "displayName": "Codestral Embed",
      "mode": "embedding",
      "source": "litellm",
      "context": {
        "maxInputTokens": 8192
      }
    },
    "codestral-embed-2505": {
      "provider": "mistral",
      "displayName": "Codestral Embed 2505",
      "mode": "embedding",
      "source": "litellm",
      "context": {
        "maxInputTokens": 8192
      }
    },
    "mistral-large-2407": {
      "provider": "mistral",
      "displayName": "Mistral Large 2407",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000009
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "mistral-large-2411": {
      "provider": "mistral",
      "displayName": "Mistral Large 2411",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "mistral-large-3": {
      "provider": "mistral",
      "displayName": "Mistral Large 3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "mistral-medium": {
      "provider": "mistral",
      "displayName": "Mistral Medium",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000027,
        "outputCostPerToken": 0.0000081
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "mistral-medium-2312": {
      "provider": "mistral",
      "displayName": "Mistral Medium 2312",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000027,
        "outputCostPerToken": 0.0000081
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "mistral-medium-2505": {
      "provider": "mistral",
      "displayName": "Mistral Medium 2505",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "mistral-medium-latest": {
      "provider": "mistral",
      "displayName": "Mistral Medium Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "mistral-small": {
      "provider": "mistral",
      "displayName": "Mistral Small",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "mistral-small-latest": {
      "provider": "mistral",
      "displayName": "Mistral Small Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "mistral-tiny": {
      "provider": "mistral",
      "displayName": "Mistral Tiny",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 2.5e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "open-codestral-mamba": {
      "provider": "mistral",
      "displayName": "Open Codestral Mamba",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 2.5e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "open-mistral-7b": {
      "provider": "mistral",
      "displayName": "Open Mistral 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 2.5e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "open-mistral-nemo": {
      "provider": "mistral",
      "displayName": "Open Mistral Nemo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "open-mistral-nemo-2407": {
      "provider": "mistral",
      "displayName": "Open Mistral Nemo 2407",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "open-mixtral-8x22b": {
      "provider": "mistral",
      "displayName": "Open Mixtral 8x22b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 65336,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "open-mixtral-8x7b": {
      "provider": "mistral",
      "displayName": "Open Mixtral 8x7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7e-7,
        "outputCostPerToken": 7e-7
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "pixtral-12b-2409": {
      "provider": "mistral",
      "displayName": "Pixtral 12b 2409",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 1.5e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "pixtral-large-2411": {
      "provider": "mistral",
      "displayName": "Pixtral Large 2411",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "pixtral-large-latest": {
      "provider": "mistral",
      "displayName": "Pixtral Large Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "multimodalembedding": {
      "provider": "google",
      "displayName": "Multimodalembedding",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 2048
      }
    },
    "multimodalembedding@001": {
      "provider": "google",
      "displayName": "Multimodalembedding@001",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 2048
      }
    },
    "o1-pro": {
      "provider": "openai",
      "displayName": "OpenAI: o1-pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00015,
        "outputCostPerToken": 0.0006
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "max_tokens"
      ]
    },
    "o1-pro-2025-03-19": {
      "provider": "openai",
      "displayName": "O1 Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00015,
        "outputCostPerToken": 0.0006
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "o3-deep-research-2025-06-26": {
      "provider": "openai",
      "displayName": "O3 Deep Research",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00004,
        "cacheReadCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "o4-mini-deep-research": {
      "provider": "openai",
      "displayName": "OpenAI: o4 Mini Deep Research",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ]
    },
    "o4-mini-deep-research-2025-06-26": {
      "provider": "openai",
      "displayName": "O4 Mini Deep Research",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "omni-moderation-2024-09-26": {
      "provider": "openai",
      "displayName": "Omni Moderation",
      "mode": "moderation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32768
      }
    },
    "omni-moderation-latest": {
      "provider": "openai",
      "displayName": "Omni Moderation Latest",
      "mode": "moderation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32768
      }
    },
    "omni-moderation-latest-intents": {
      "provider": "openai",
      "displayName": "Omni Moderation Latest Intents",
      "mode": "moderation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32768
      }
    },
    "codellama-34b-instruct": {
      "provider": "perplexity",
      "displayName": "Codellama 34b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3.5e-7,
        "outputCostPerToken": 0.0000014
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "codellama-70b-instruct": {
      "provider": "perplexity",
      "displayName": "Codellama 70b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7e-7,
        "outputCostPerToken": 0.0000028
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "llama-2-70b-chat": {
      "provider": "perplexity",
      "displayName": "Llama 2 70b Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7e-7,
        "outputCostPerToken": 0.0000028
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "llama-3.1-70b-instruct": {
      "provider": "perplexity",
      "displayName": "Llama 3.1 70b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000001
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "llama-3.1-8b-instruct": {
      "provider": "perplexity",
      "displayName": "Llama 3.1 8b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "llama-3.1-sonar-huge-128k-online": {
      "provider": "perplexity",
      "displayName": "Llama 3.1 Sonar Huge 128k Online",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 127072,
        "maxOutputTokens": 127072
      },
      "deprecationDate": "2025-02-22"
    },
    "llama-3.1-sonar-large-128k-chat": {
      "provider": "perplexity",
      "displayName": "Llama 3.1 Sonar Large 128k Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000001
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "deprecationDate": "2025-02-22"
    },
    "llama-3.1-sonar-large-128k-online": {
      "provider": "perplexity",
      "displayName": "Llama 3.1 Sonar Large 128k Online",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000001
      },
      "context": {
        "maxInputTokens": 127072,
        "maxOutputTokens": 127072
      },
      "deprecationDate": "2025-02-22"
    },
    "llama-3.1-sonar-small-128k-chat": {
      "provider": "perplexity",
      "displayName": "Llama 3.1 Sonar Small 128k Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "deprecationDate": "2025-02-22"
    },
    "llama-3.1-sonar-small-128k-online": {
      "provider": "perplexity",
      "displayName": "Llama 3.1 Sonar Small 128k Online",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 127072,
        "maxOutputTokens": 127072
      },
      "deprecationDate": "2025-02-22"
    },
    "mistral-7b-instruct": {
      "provider": "perplexity",
      "displayName": "Mistral 7b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7e-8,
        "outputCostPerToken": 2.8e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "mixtral-8x7b-instruct": {
      "provider": "perplexity",
      "displayName": "Mixtral 8x7b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7e-8,
        "outputCostPerToken": 2.8e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "pplx-70b-chat": {
      "provider": "perplexity",
      "displayName": "Pplx 70b Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7e-7,
        "outputCostPerToken": 0.0000028
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "pplx-70b-online": {
      "provider": "perplexity",
      "displayName": "Pplx 70b Online",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0.0000028
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "pplx-7b-chat": {
      "provider": "perplexity",
      "displayName": "Pplx 7b Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7e-8,
        "outputCostPerToken": 2.8e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "pplx-7b-online": {
      "provider": "perplexity",
      "displayName": "Pplx 7b Online",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 2.8e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "sonar": {
      "provider": "perplexity",
      "displayName": "Perplexity: Sonar",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000001
      },
      "context": {
        "maxInputTokens": 128000
      },
      "capabilities": {
        "webSearch": true,
        "vision": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ]
    },
    "sonar-deep-research": {
      "provider": "perplexity",
      "displayName": "Perplexity: Sonar Deep Research",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008
      },
      "context": {
        "maxInputTokens": 128000
      },
      "capabilities": {
        "reasoning": true,
        "webSearch": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ]
    },
    "sonar-medium-chat": {
      "provider": "perplexity",
      "displayName": "Sonar Medium Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000018
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "sonar-medium-online": {
      "provider": "perplexity",
      "displayName": "Sonar Medium Online",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0.0000018
      },
      "context": {
        "maxInputTokens": 12000,
        "maxOutputTokens": 12000
      }
    },
    "sonar-pro": {
      "provider": "perplexity",
      "displayName": "Perplexity: Sonar Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8000
      },
      "capabilities": {
        "webSearch": true,
        "vision": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ]
    },
    "sonar-reasoning": {
      "provider": "perplexity",
      "displayName": "Sonar Reasoning",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 128000
      },
      "capabilities": {
        "reasoning": true,
        "webSearch": true
      }
    },
    "sonar-reasoning-pro": {
      "provider": "perplexity",
      "displayName": "Perplexity: Sonar Reasoning Pro",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008
      },
      "context": {
        "maxInputTokens": 128000
      },
      "capabilities": {
        "reasoning": true,
        "webSearch": true,
        "vision": true
      },
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ]
    },
    "sonar-small-chat": {
      "provider": "perplexity",
      "displayName": "Sonar Small Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7e-8,
        "outputCostPerToken": 2.8e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "sonar-small-online": {
      "provider": "perplexity",
      "displayName": "Sonar Small Online",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 2.8e-7
      },
      "context": {
        "maxInputTokens": 12000,
        "maxOutputTokens": 12000
      }
    },
    "preset/pro-search": {
      "provider": "perplexity",
      "displayName": "Preset/pro Search",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "webSearch": true
      }
    },
    "openai/gpt-4o": {
      "provider": "perplexity",
      "displayName": "Openai/gpt 4o",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "reasoning": false,
        "webSearch": true
      }
    },
    "openai/gpt-4o-mini": {
      "provider": "perplexity",
      "displayName": "Openai/gpt 4o Mini",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "reasoning": false,
        "webSearch": true
      }
    },
    "openai/gpt-5.2": {
      "provider": "perplexity",
      "displayName": "Openai/gpt 5.2",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "reasoning": true,
        "webSearch": true
      }
    },
    "anthropic/claude-3-5-sonnet-20241022": {
      "provider": "perplexity",
      "displayName": "Anthropic/claude 3 5 Sonnet",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "reasoning": false,
        "webSearch": true
      }
    },
    "anthropic/claude-3-5-haiku-20241022": {
      "provider": "perplexity",
      "displayName": "Anthropic/claude 3 5 Haiku",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "reasoning": false,
        "webSearch": true
      }
    },
    "google/gemini-2.0-flash-exp": {
      "provider": "perplexity",
      "displayName": "Google/gemini 2.0 Flash Exp",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "reasoning": false,
        "webSearch": true
      }
    },
    "google/gemini-2.0-flash-thinking-exp": {
      "provider": "perplexity",
      "displayName": "Google/gemini 2.0 Flash Thinking Exp",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "reasoning": true,
        "webSearch": true
      }
    },
    "xai/grok-2-1212": {
      "provider": "perplexity",
      "displayName": "Xai/grok 2 1212",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "reasoning": false,
        "webSearch": true
      }
    },
    "xai/grok-2-vision-1212": {
      "provider": "perplexity",
      "displayName": "Xai/grok 2 Vision 1212",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "reasoning": false,
        "webSearch": true
      }
    },
    "rerank-english-v2.0": {
      "provider": "cohere",
      "displayName": "Rerank English V2.0",
      "mode": "rerank",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "rerank-english-v3.0": {
      "provider": "cohere",
      "displayName": "Rerank English V3.0",
      "mode": "rerank",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "rerank-multilingual-v2.0": {
      "provider": "cohere",
      "displayName": "Rerank Multilingual V2.0",
      "mode": "rerank",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "rerank-multilingual-v3.0": {
      "provider": "cohere",
      "displayName": "Rerank Multilingual V3.0",
      "mode": "rerank",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "rerank-v3.5": {
      "provider": "cohere",
      "displayName": "Rerank V3.5",
      "mode": "rerank",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "stability.sd3-5-large-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.sd3 5 Large V1:0",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.sd3-large-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.sd3 Large V1:0",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-core-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Core V1:0",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-conservative-upscale-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Conservative Upscale V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-creative-upscale-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Creative Upscale V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-fast-upscale-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Fast Upscale V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-outpaint-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Outpaint V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-control-sketch-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Control Sketch V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-control-structure-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Control Structure V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-erase-object-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Erase Object V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-inpaint-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Inpaint V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-remove-background-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Remove Background V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-search-recolor-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Search Recolor V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-search-replace-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Search Replace V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-style-guide-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Style Guide V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-style-transfer-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Style Transfer V1:0",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-core-v1:1": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Core V1:1",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-ultra-v1:0": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Ultra V1:0",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "stability.stable-image-ultra-v1:1": {
      "provider": "bedrock",
      "displayName": "Stability.stable Image Ultra V1:1",
      "mode": "image_generation",
      "source": "litellm",
      "context": {
        "maxInputTokens": 77
      }
    },
    "text-bison": {
      "provider": "google",
      "displayName": "Text Bison",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 2048
      }
    },
    "text-bison32k": {
      "provider": "google",
      "displayName": "Text Bison32k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 1024
      }
    },
    "text-bison32k@002": {
      "provider": "google",
      "displayName": "Text Bison32k@002",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.25e-7,
        "outputCostPerToken": 1.25e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 1024
      }
    },
    "text-bison@001": {
      "provider": "google",
      "displayName": "Text Bison@001",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 1024
      }
    },
    "text-bison@002": {
      "provider": "google",
      "displayName": "Text Bison@002",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 1024
      }
    },
    "text-embedding-004": {
      "provider": "google",
      "displayName": "Text Embedding 004",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 2048
      },
      "deprecationDate": "2026-01-14"
    },
    "text-embedding-005": {
      "provider": "google",
      "displayName": "Text Embedding 005",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 2048
      }
    },
    "text-embedding-ada-002-v2": {
      "provider": "openai",
      "displayName": "Text Embedding Ada 002 V2",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8191
      }
    },
    "text-embedding-large-exp-03-07": {
      "provider": "google",
      "displayName": "Text Embedding Large Exp 03 07",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8192
      }
    },
    "text-embedding-preview-0409": {
      "provider": "google",
      "displayName": "Text Embedding Preview 0409",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6.25e-9,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 3072
      }
    },
    "text-moderation-007": {
      "provider": "openai",
      "displayName": "Text Moderation 007",
      "mode": "moderation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32768
      }
    },
    "text-moderation-latest": {
      "provider": "openai",
      "displayName": "Text Moderation Latest",
      "mode": "moderation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32768
      }
    },
    "text-moderation-stable": {
      "provider": "openai",
      "displayName": "Text Moderation Stable",
      "mode": "moderation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32768
      }
    },
    "text-multilingual-embedding-002": {
      "provider": "google",
      "displayName": "Text Multilingual Embedding 002",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 2048
      }
    },
    "text-multilingual-embedding-preview-0409": {
      "provider": "google",
      "displayName": "Text Multilingual Embedding Preview 0409",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6.25e-9,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 3072
      }
    },
    "text-unicorn": {
      "provider": "google",
      "displayName": "Text Unicorn",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.000028
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 1024
      }
    },
    "text-unicorn@001": {
      "provider": "google",
      "displayName": "Text Unicorn@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.000028
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 1024
      }
    },
    "textembedding-gecko": {
      "provider": "google",
      "displayName": "Textembedding Gecko",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 3072
      }
    },
    "textembedding-gecko-multilingual": {
      "provider": "google",
      "displayName": "Textembedding Gecko Multilingual",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 3072
      }
    },
    "textembedding-gecko-multilingual@001": {
      "provider": "google",
      "displayName": "Textembedding Gecko Multilingual@001",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 3072
      }
    },
    "textembedding-gecko@001": {
      "provider": "google",
      "displayName": "Textembedding Gecko@001",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 3072
      }
    },
    "textembedding-gecko@003": {
      "provider": "google",
      "displayName": "Textembedding Gecko@003",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 3072
      }
    },
    "together-ai-21.1b-41b": {
      "provider": "together_ai",
      "displayName": "Together Ai 21.1b 41b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 8e-7
      }
    },
    "together-ai-4.1b-8b": {
      "provider": "together_ai",
      "displayName": "Together Ai 4.1b 8b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      }
    },
    "together-ai-41.1b-80b": {
      "provider": "together_ai",
      "displayName": "Together Ai 41.1b 80b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      }
    },
    "together-ai-8.1b-21b": {
      "provider": "together_ai",
      "displayName": "Together Ai 8.1b 21b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 1000
      }
    },
    "together-ai-81.1b-110b": {
      "provider": "together_ai",
      "displayName": "Together Ai 81.1b 110b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000018,
        "outputCostPerToken": 0.0000018
      }
    },
    "together-ai-embedding-151m-to-350m": {
      "provider": "together_ai",
      "displayName": "Together Ai Embedding 151m To 350m",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.6e-8,
        "outputCostPerToken": 0
      }
    },
    "together-ai-embedding-up-to-150m": {
      "provider": "together_ai",
      "displayName": "Together Ai Embedding Up To 150m",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-9,
        "outputCostPerToken": 0
      }
    },
    "baai/bge-base-en-v1.5": {
      "provider": "together_ai",
      "displayName": "Baai/bge Base En V1.5",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-9,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 512
      }
    },
    "BAAI/bge-base-en-v1.5": {
      "provider": "together_ai",
      "displayName": "BAAI/bge Base En V1.5",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-9,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 512
      }
    },
    "together-ai-up-to-4b": {
      "provider": "together_ai",
      "displayName": "Together Ai Up To 4b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      }
    },
    "Qwen/Qwen2.5-72B-Instruct-Turbo": {
      "provider": "together_ai",
      "displayName": "Qwen/Qwen2.5 72B Instruct Turbo",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "Qwen/Qwen2.5-7B-Instruct-Turbo": {
      "provider": "together_ai",
      "displayName": "Qwen/Qwen2.5 7B Instruct Turbo",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "Qwen/Qwen3-235B-A22B-Instruct-2507-tput": {
      "provider": "together_ai",
      "displayName": "Qwen/Qwen3 235B A22B Instruct 2507 Tput",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 262000
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "provider": "together_ai",
      "displayName": "Qwen/Qwen3 235B A22B Thinking 2507",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6.5e-7,
        "outputCostPerToken": 0.000003
      },
      "context": {
        "maxInputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "Qwen/Qwen3-235B-A22B-fp8-tput": {
      "provider": "together_ai",
      "displayName": "Qwen/Qwen3 235B A22B Fp8 Tput",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 40000
      },
      "capabilities": {
        "functionCalling": false,
        "parallelFunctionCalling": false
      }
    },
    "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "provider": "together_ai",
      "displayName": "Qwen/Qwen3 Coder 480B A35B Instruct FP8",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-ai/DeepSeek-R1": {
      "provider": "together_ai",
      "displayName": "Deepseek Ai/DeepSeek R1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000007
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 20480
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-ai/DeepSeek-R1-0528-tput": {
      "provider": "together_ai",
      "displayName": "Deepseek Ai/DeepSeek R1 0528 Tput",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.5e-7,
        "outputCostPerToken": 0.00000219
      },
      "context": {
        "maxInputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-ai/DeepSeek-V3": {
      "provider": "together_ai",
      "displayName": "Deepseek Ai/DeepSeek V3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-ai/DeepSeek-V3.1": {
      "provider": "together_ai",
      "displayName": "Deepseek Ai/DeepSeek V3.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000017
      },
      "context": {
        "maxInputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "reasoning": true
      }
    },
    "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
      "provider": "together_ai",
      "displayName": "Meta Llama/Llama 3.2 3B Instruct Turbo",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "provider": "together_ai",
      "displayName": "Meta Llama/Llama 3.3 70B Instruct Turbo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8.8e-7,
        "outputCostPerToken": 8.8e-7
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": {
      "provider": "together_ai",
      "displayName": "Meta Llama/Llama 3.3 70B Instruct Turbo Free",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "provider": "together_ai",
      "displayName": "Meta Llama/Llama 4 Maverick 17B 128E Instruct FP8",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.7e-7,
        "outputCostPerToken": 8.5e-7
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "provider": "together_ai",
      "displayName": "Meta Llama/Llama 4 Scout 17B 16E Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.8e-7,
        "outputCostPerToken": 5.9e-7
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
      "provider": "together_ai",
      "displayName": "Meta Llama/Meta Llama 3.1 405B Instruct Turbo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000035,
        "outputCostPerToken": 0.0000035
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
      "provider": "together_ai",
      "displayName": "Meta Llama/Meta Llama 3.1 70B Instruct Turbo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8.8e-7,
        "outputCostPerToken": 8.8e-7
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
      "provider": "together_ai",
      "displayName": "Meta Llama/Meta Llama 3.1 8B Instruct Turbo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.8e-7,
        "outputCostPerToken": 1.8e-7
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "mistralai/Mistral-7B-Instruct-v0.1": {
      "provider": "together_ai",
      "displayName": "Mistralai/Mistral 7B Instruct V0.1",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "mistralai/Mistral-Small-24B-Instruct-2501": {
      "provider": "together_ai",
      "displayName": "Mistralai/Mistral Small 24B Instruct 2501",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      }
    },
    "mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "provider": "together_ai",
      "displayName": "Mistralai/Mixtral 8x7B Instruct V0.1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 6e-7
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "moonshotai/Kimi-K2-Instruct": {
      "provider": "together_ai",
      "displayName": "Moonshotai/Kimi K2 Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000003
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "togethercomputer/CodeLlama-34b-Instruct": {
      "provider": "together_ai",
      "displayName": "Togethercomputer/CodeLlama 34b Instruct",
      "mode": "chat",
      "source": "litellm",
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      }
    },
    "zai-org/GLM-4.5-Air-FP8": {
      "provider": "together_ai",
      "displayName": "Zai Org/GLM 4.5 Air FP8",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 0.0000011
      },
      "context": {
        "maxInputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "zai-org/GLM-4.6": {
      "provider": "together_ai",
      "displayName": "Zai Org/GLM 4.6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000022
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 200000
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "reasoning": true
      }
    },
    "zai-org/GLM-4.7": {
      "provider": "together_ai",
      "displayName": "Zai Org/GLM 4.7",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4.5e-7,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 200000
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "reasoning": true
      }
    },
    "moonshotai/Kimi-K2.5": {
      "provider": "together_ai",
      "displayName": "Moonshotai/Kimi K2.5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 0.0000028
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "reasoning": true
      }
    },
    "moonshotai/Kimi-K2-Instruct-0905": {
      "provider": "together_ai",
      "displayName": "Moonshotai/Kimi K2 Instruct 0905",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000003
      },
      "context": {
        "maxInputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true
      }
    },
    "Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "provider": "together_ai",
      "displayName": "Qwen/Qwen3 Next 80B A3B Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "provider": "together_ai",
      "displayName": "Qwen/Qwen3 Next 80B A3B Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true
      }
    },
    "us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "provider": "bedrock",
      "displayName": "Us.anthropic.claude 3 5 Sonnet 20241022 V2:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "pdfInput": true
      }
    },
    "us.anthropic.claude-3-haiku-20240307-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.anthropic.claude 3 Haiku 20240307 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "us.anthropic.claude-3-opus-20240229-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.anthropic.claude 3 Opus 20240229 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "us.anthropic.claude-3-sonnet-20240229-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.anthropic.claude 3 Sonnet 20240229 V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "pdfInput": true
      }
    },
    "us.meta.llama3-1-405b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.meta.llama3 1 405b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000532,
        "outputCostPerToken": 0.000016
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "us.meta.llama3-1-70b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.meta.llama3 1 70b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9.9e-7,
        "outputCostPerToken": 9.9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "us.meta.llama3-1-8b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.meta.llama3 1 8b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.2e-7,
        "outputCostPerToken": 2.2e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "us.meta.llama3-2-11b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.meta.llama3 2 11b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3.5e-7,
        "outputCostPerToken": 3.5e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "us.meta.llama3-2-1b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.meta.llama3 2 1b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "us.meta.llama3-2-3b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.meta.llama3 2 3b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 1.5e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "us.meta.llama3-2-90b-instruct-v1:0": {
      "provider": "bedrock",
      "displayName": "Us.meta.llama3 2 90b Instruct V1:0",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "chirp": {
      "provider": "google",
      "displayName": "Chirp",
      "mode": "audio_speech",
      "source": "litellm"
    },
    "vertex_ai/claude-3-5-haiku": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 5 Haiku",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-3-5-haiku@20241022": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 5 Haiku@20241022",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-haiku-4-5@20251001": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Haiku 4 5@20251001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000005,
        "cacheCreationCostPerToken": 0.00000125,
        "cacheReadCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-3-5-sonnet": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 5 Sonnet",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-3-5-sonnet-v2": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 5 Sonnet V2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-3-5-sonnet-v2@20241022": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 5 Sonnet V2@20241022",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-3-5-sonnet@20240620": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 5 Sonnet@20240620",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-3-7-sonnet@20250219": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 7 Sonnet@20250219",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      },
      "deprecationDate": "2025-06-01"
    },
    "vertex_ai/claude-3-haiku": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 Haiku",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "vertex_ai/claude-3-haiku@20240307": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 Haiku@20240307",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "vertex_ai/claude-3-opus": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 Opus",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "vertex_ai/claude-3-opus@20240229": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 Opus@20240229",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "vertex_ai/claude-3-sonnet": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 Sonnet",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "vertex_ai/claude-3-sonnet@20240229": {
      "provider": "google",
      "displayName": "Vertex Ai/claude 3 Sonnet@20240229",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "vertex_ai/claude-opus-4": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Opus 4",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075,
        "cacheCreationCostPerToken": 0.00001875,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 32000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-opus-4-1": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Opus 4 1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075,
        "cacheCreationCostPerToken": 0.00001875,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 32000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "vertex_ai/claude-opus-4-1@20250805": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Opus 4 1@20250805",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075,
        "cacheCreationCostPerToken": 0.00001875,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 32000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "vertex_ai/claude-opus-4-5": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Opus 4 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025,
        "cacheCreationCostPerToken": 0.00000625,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-opus-4-5@20251101": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Opus 4 5@20251101",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025,
        "cacheCreationCostPerToken": 0.00000625,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-opus-4-6": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Opus 4 6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025,
        "cacheCreationCostPerToken": 0.00000625,
        "cacheReadCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-sonnet-4-5": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Sonnet 4 5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-sonnet-4-5@20250929": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Sonnet 4 5@20250929",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-opus-4@20250514": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Opus 4@20250514",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075,
        "cacheCreationCostPerToken": 0.00001875,
        "cacheReadCostPerToken": 0.0000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 32000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-sonnet-4": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Sonnet 4",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "vertex_ai/claude-sonnet-4@20250514": {
      "provider": "google",
      "displayName": "Vertex Ai/claude Sonnet 4@20250514",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheCreationCostPerToken": 0.00000375,
        "cacheReadCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "reasoning": true,
        "pdfInput": true
      }
    },
    "vertex_ai/mistralai/codestral-2@001": {
      "provider": "google",
      "displayName": "Vertex Ai/mistralai/codestral 2@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/codestral-2": {
      "provider": "google",
      "displayName": "Vertex Ai/codestral 2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/codestral-2@001": {
      "provider": "google",
      "displayName": "Vertex Ai/codestral 2@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistralai/codestral-2": {
      "provider": "google",
      "displayName": "Vertex Ai/mistralai/codestral 2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/codestral-2501": {
      "provider": "google",
      "displayName": "Vertex Ai/codestral 2501",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/codestral@2405": {
      "provider": "google",
      "displayName": "Vertex Ai/codestral@2405",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/codestral@latest": {
      "provider": "google",
      "displayName": "Vertex Ai/codestral@latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/deepseek-ai/deepseek-v3.1-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/deepseek Ai/deepseek V3.1 Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000135,
        "outputCostPerToken": 0.0000054
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true,
        "reasoning": true
      }
    },
    "vertex_ai/deepseek-ai/deepseek-v3.2-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/deepseek Ai/deepseek V3.2 Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5.6e-7,
        "outputCostPerToken": 0.00000168
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true,
        "reasoning": true
      }
    },
    "vertex_ai/deepseek-ai/deepseek-r1-0528-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/deepseek Ai/deepseek R1 0528 Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.00000135,
        "outputCostPerToken": 0.0000054
      },
      "context": {
        "maxInputTokens": 65336,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "functionCalling": true,
        "promptCaching": true,
        "reasoning": true
      }
    },
    "vertex_ai/gemini-2.5-flash-image": {
      "provider": "google",
      "displayName": "Vertex Ai/gemini 2.5 Flash Image",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000025,
        "cacheReadCostPerToken": 3e-8
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "parallelFunctionCalling": true,
        "structuredOutput": true,
        "promptCaching": true,
        "audioOutput": false,
        "pdfInput": true,
        "webSearch": false
      }
    },
    "vertex_ai/gemini-3-pro-image-preview": {
      "provider": "google",
      "displayName": "Vertex Ai/gemini 3 Pro Image Preview",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000012
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 32768
      }
    },
    "vertex_ai/deep-research-pro-preview-12-2025": {
      "provider": "google",
      "displayName": "Vertex Ai/deep Research Pro Preview 12 2025",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000012
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 32768
      }
    },
    "vertex_ai/imagegeneration@006": {
      "provider": "google",
      "displayName": "Vertex Ai/imagegeneration@006",
      "mode": "image_generation",
      "source": "litellm"
    },
    "vertex_ai/imagen-3.0-fast-generate-001": {
      "provider": "google",
      "displayName": "Vertex Ai/imagen 3.0 Fast Generate 001",
      "mode": "image_generation",
      "source": "litellm"
    },
    "vertex_ai/imagen-3.0-generate-001": {
      "provider": "google",
      "displayName": "Vertex Ai/imagen 3.0 Generate 001",
      "mode": "image_generation",
      "source": "litellm"
    },
    "vertex_ai/imagen-3.0-generate-002": {
      "provider": "google",
      "displayName": "Vertex Ai/imagen 3.0 Generate 002",
      "mode": "image_generation",
      "source": "litellm",
      "deprecationDate": "2025-11-10"
    },
    "vertex_ai/imagen-3.0-capability-001": {
      "provider": "google",
      "displayName": "Vertex Ai/imagen 3.0 Capability 001",
      "mode": "image_generation",
      "source": "litellm"
    },
    "vertex_ai/imagen-4.0-fast-generate-001": {
      "provider": "google",
      "displayName": "Vertex Ai/imagen 4.0 Fast Generate 001",
      "mode": "image_generation",
      "source": "litellm"
    },
    "vertex_ai/imagen-4.0-generate-001": {
      "provider": "google",
      "displayName": "Vertex Ai/imagen 4.0 Generate 001",
      "mode": "image_generation",
      "source": "litellm"
    },
    "vertex_ai/imagen-4.0-ultra-generate-001": {
      "provider": "google",
      "displayName": "Vertex Ai/imagen 4.0 Ultra Generate 001",
      "mode": "image_generation",
      "source": "litellm"
    },
    "vertex_ai/jamba-1.5": {
      "provider": "google",
      "displayName": "Vertex Ai/jamba 1.5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 4e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "vertex_ai/jamba-1.5-large": {
      "provider": "google",
      "displayName": "Vertex Ai/jamba 1.5 Large",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "vertex_ai/jamba-1.5-large@001": {
      "provider": "google",
      "displayName": "Vertex Ai/jamba 1.5 Large@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000008
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "vertex_ai/jamba-1.5-mini": {
      "provider": "google",
      "displayName": "Vertex Ai/jamba 1.5 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 4e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "vertex_ai/jamba-1.5-mini@001": {
      "provider": "google",
      "displayName": "Vertex Ai/jamba 1.5 Mini@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 4e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "vertex_ai/meta/llama-3.1-405b-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama 3.1 405b Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000016
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "vision": true
      }
    },
    "vertex_ai/meta/llama-3.1-70b-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama 3.1 70b Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "vision": true
      }
    },
    "vertex_ai/meta/llama-3.1-8b-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama 3.1 8b Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "vision": true
      }
    },
    "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama 3.2 90b Vision Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "vision": true
      }
    },
    "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama 4 Maverick 17b 128e Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3.5e-7,
        "outputCostPerToken": 0.00000115
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 1000000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama 4 Maverick 17b 16e Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3.5e-7,
        "outputCostPerToken": 0.00000115
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 1000000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama 4 Scout 17b 128e Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 7e-7
      },
      "context": {
        "maxInputTokens": 10000000,
        "maxOutputTokens": 10000000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama 4 Scout 17b 16e Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 7e-7
      },
      "context": {
        "maxInputTokens": 10000000,
        "maxOutputTokens": 10000000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/meta/llama3-405b-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama3 405b Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 32000
      }
    },
    "vertex_ai/meta/llama3-70b-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama3 70b Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 32000
      }
    },
    "vertex_ai/meta/llama3-8b-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/meta/llama3 8b Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 32000
      }
    },
    "vertex_ai/minimaxai/minimax-m2-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/minimaxai/minimax M2 Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 196608,
        "maxOutputTokens": 196608
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/moonshotai/kimi-k2-thinking-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/moonshotai/kimi K2 Thinking Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000025
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "webSearch": true
      }
    },
    "vertex_ai/zai-org/glm-4.7-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/zai Org/glm 4.7 Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.0000022
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "vertex_ai/mistral-medium-3": {
      "provider": "google",
      "displayName": "Vertex Ai/mistral Medium 3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistral-medium-3@001": {
      "provider": "google",
      "displayName": "Vertex Ai/mistral Medium 3@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistralai/mistral-medium-3": {
      "provider": "google",
      "displayName": "Vertex Ai/mistralai/mistral Medium 3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistralai/mistral-medium-3@001": {
      "provider": "google",
      "displayName": "Vertex Ai/mistralai/mistral Medium 3@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistral-large-2411": {
      "provider": "google",
      "displayName": "Vertex Ai/mistral Large 2411",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistral-large@2407": {
      "provider": "google",
      "displayName": "Vertex Ai/mistral Large@2407",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistral-large@2411-001": {
      "provider": "google",
      "displayName": "Vertex Ai/mistral Large@2411 001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistral-large@latest": {
      "provider": "google",
      "displayName": "Vertex Ai/mistral Large@latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.000006
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistral-nemo@2407": {
      "provider": "google",
      "displayName": "Vertex Ai/mistral Nemo@2407",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistral-nemo@latest": {
      "provider": "google",
      "displayName": "Vertex Ai/mistral Nemo@latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 1.5e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/mistral-small-2503": {
      "provider": "google",
      "displayName": "Vertex Ai/mistral Small 2503",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000003
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "vertex_ai/mistral-small-2503@001": {
      "provider": "google",
      "displayName": "Vertex Ai/mistral Small 2503@001",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000003
      },
      "context": {
        "maxInputTokens": 32000,
        "maxOutputTokens": 8191
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "mistral-ocr-2505": {
      "provider": "google",
      "displayName": "Mistral Ocr 2505",
      "mode": "chat",
      "source": "litellm"
    },
    "deepseek-ai/deepseek-ocr-maas": {
      "provider": "google",
      "displayName": "Deepseek Ai/deepseek Ocr Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000012
      }
    },
    "vertex_ai/openai/gpt-oss-120b-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/openai/gpt Oss 120b Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "reasoning": true
      }
    },
    "vertex_ai/openai/gpt-oss-20b-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/openai/gpt Oss 20b Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 7.5e-8,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "reasoning": true
      }
    },
    "vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/qwen/qwen3 235b A22b Instruct 2507 Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.000001
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 16384
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/qwen/qwen3 Coder 480b A35b Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000004
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/qwen/qwen3 Next 80b A3b Instruct Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas": {
      "provider": "google",
      "displayName": "Vertex Ai/qwen/qwen3 Next 80b A3b Thinking Maas",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "vertex_ai/veo-2.0-generate-001": {
      "provider": "google",
      "displayName": "Vertex Ai/veo 2.0 Generate 001",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 1024
      }
    },
    "vertex_ai/veo-3.0-fast-generate-preview": {
      "provider": "google",
      "displayName": "Vertex Ai/veo 3.0 Fast Generate Preview",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 1024
      },
      "deprecationDate": "2025-11-12"
    },
    "vertex_ai/veo-3.0-generate-preview": {
      "provider": "google",
      "displayName": "Vertex Ai/veo 3.0 Generate Preview",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 1024
      },
      "deprecationDate": "2025-11-12"
    },
    "vertex_ai/veo-3.0-fast-generate-001": {
      "provider": "google",
      "displayName": "Vertex Ai/veo 3.0 Fast Generate 001",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 1024
      }
    },
    "vertex_ai/veo-3.0-generate-001": {
      "provider": "google",
      "displayName": "Vertex Ai/veo 3.0 Generate 001",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 1024
      }
    },
    "vertex_ai/veo-3.1-generate-preview": {
      "provider": "google",
      "displayName": "Vertex Ai/veo 3.1 Generate Preview",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 1024
      }
    },
    "vertex_ai/veo-3.1-fast-generate-preview": {
      "provider": "google",
      "displayName": "Vertex Ai/veo 3.1 Fast Generate Preview",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 1024
      }
    },
    "vertex_ai/veo-3.1-generate-001": {
      "provider": "google",
      "displayName": "Vertex Ai/veo 3.1 Generate 001",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 1024
      }
    },
    "vertex_ai/veo-3.1-fast-generate-001": {
      "provider": "google",
      "displayName": "Vertex Ai/veo 3.1 Fast Generate 001",
      "mode": "chat",
      "source": "litellm",
      "context": {
        "maxInputTokens": 1024
      }
    },
    "grok-2": {
      "provider": "xai",
      "displayName": "Grok 2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-2-1212": {
      "provider": "xai",
      "displayName": "Grok 2 1212",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-2-latest": {
      "provider": "xai",
      "displayName": "Grok 2 Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-2-vision": {
      "provider": "xai",
      "displayName": "Grok 2 Vision",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-2-vision-1212": {
      "provider": "xai",
      "displayName": "Grok 2 Vision 1212",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-2-vision-latest": {
      "provider": "xai",
      "displayName": "Grok 2 Vision Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000002,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-3": {
      "provider": "xai",
      "displayName": "Grok 3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheReadCostPerToken": 7.5e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "webSearch": true
      }
    },
    "grok-3-beta": {
      "provider": "xai",
      "displayName": "Grok 3 Beta",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheReadCostPerToken": 7.5e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "webSearch": true
      }
    },
    "grok-3-fast-beta": {
      "provider": "xai",
      "displayName": "Grok 3 Fast Beta",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "webSearch": true
      }
    },
    "grok-3-fast-latest": {
      "provider": "xai",
      "displayName": "Grok 3 Fast Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025,
        "cacheReadCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "webSearch": true
      }
    },
    "grok-3-latest": {
      "provider": "xai",
      "displayName": "Grok 3 Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015,
        "cacheReadCostPerToken": 7.5e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "webSearch": true
      }
    },
    "grok-3-mini": {
      "provider": "xai",
      "displayName": "Grok 3 Mini",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 5e-7,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "reasoning": true,
        "webSearch": true
      }
    },
    "grok-3-mini-beta": {
      "provider": "xai",
      "displayName": "Grok 3 Mini Beta",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 5e-7,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "reasoning": true,
        "webSearch": true
      }
    },
    "grok-3-mini-fast": {
      "provider": "xai",
      "displayName": "Grok 3 Mini Fast",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.000004,
        "cacheReadCostPerToken": 1.5e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "reasoning": true,
        "webSearch": true
      }
    },
    "grok-3-mini-fast-beta": {
      "provider": "xai",
      "displayName": "Grok 3 Mini Fast Beta",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.000004,
        "cacheReadCostPerToken": 1.5e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "reasoning": true,
        "webSearch": true
      }
    },
    "grok-3-mini-fast-latest": {
      "provider": "xai",
      "displayName": "Grok 3 Mini Fast Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 6e-7,
        "outputCostPerToken": 0.000004,
        "cacheReadCostPerToken": 1.5e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "reasoning": true,
        "webSearch": true
      }
    },
    "grok-3-mini-latest": {
      "provider": "xai",
      "displayName": "Grok 3 Mini Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 5e-7,
        "cacheReadCostPerToken": 7.5e-8
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": false,
        "reasoning": true,
        "webSearch": true
      }
    },
    "grok-4": {
      "provider": "xai",
      "displayName": "Grok 4",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-4-fast-reasoning": {
      "provider": "xai",
      "displayName": "Grok 4 Fast Reasoning",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 5e-7,
        "cacheReadCostPerToken": 5e-8
      },
      "context": {
        "maxInputTokens": 2000000,
        "maxOutputTokens": 2000000
      },
      "capabilities": {
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-4-fast-non-reasoning": {
      "provider": "xai",
      "displayName": "Grok 4 Fast Non Reasoning",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 5e-7,
        "cacheReadCostPerToken": 5e-8
      },
      "context": {
        "maxInputTokens": 2000000,
        "maxOutputTokens": 2000000
      },
      "capabilities": {
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-4-0709": {
      "provider": "xai",
      "displayName": "Grok 4 0709",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-4-latest": {
      "provider": "xai",
      "displayName": "Grok 4 Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-4-1-fast": {
      "provider": "xai",
      "displayName": "Grok 4 1 Fast",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 5e-7,
        "cacheReadCostPerToken": 5e-8
      },
      "context": {
        "maxInputTokens": 2000000,
        "maxOutputTokens": 2000000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true,
        "audioInput": true,
        "webSearch": true
      }
    },
    "grok-4-1-fast-reasoning": {
      "provider": "xai",
      "displayName": "Grok 4 1 Fast Reasoning",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 5e-7,
        "cacheReadCostPerToken": 5e-8
      },
      "context": {
        "maxInputTokens": 2000000,
        "maxOutputTokens": 2000000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true,
        "audioInput": true,
        "webSearch": true
      }
    },
    "grok-4-1-fast-reasoning-latest": {
      "provider": "xai",
      "displayName": "Grok 4 1 Fast Reasoning Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 5e-7,
        "cacheReadCostPerToken": 5e-8
      },
      "context": {
        "maxInputTokens": 2000000,
        "maxOutputTokens": 2000000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "reasoning": true,
        "audioInput": true,
        "webSearch": true
      }
    },
    "grok-4-1-fast-non-reasoning": {
      "provider": "xai",
      "displayName": "Grok 4 1 Fast Non Reasoning",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 5e-7,
        "cacheReadCostPerToken": 5e-8
      },
      "context": {
        "maxInputTokens": 2000000,
        "maxOutputTokens": 2000000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "audioInput": true,
        "webSearch": true
      }
    },
    "grok-4-1-fast-non-reasoning-latest": {
      "provider": "xai",
      "displayName": "Grok 4 1 Fast Non Reasoning Latest",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 5e-7,
        "cacheReadCostPerToken": 5e-8
      },
      "context": {
        "maxInputTokens": 2000000,
        "maxOutputTokens": 2000000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true,
        "audioInput": true,
        "webSearch": true
      }
    },
    "grok-beta": {
      "provider": "xai",
      "displayName": "Grok Beta",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "webSearch": true
      }
    },
    "grok-code-fast": {
      "provider": "xai",
      "displayName": "Grok Code Fast",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 0.0000015,
        "cacheReadCostPerToken": 2e-8
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "grok-code-fast-1": {
      "provider": "xai",
      "displayName": "Grok Code Fast 1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 0.0000015,
        "cacheReadCostPerToken": 2e-8
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "grok-code-fast-1-0825": {
      "provider": "xai",
      "displayName": "Grok Code Fast 1 0825",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 0.0000015,
        "cacheReadCostPerToken": 2e-8
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      },
      "capabilities": {
        "functionCalling": true,
        "reasoning": true
      }
    },
    "grok-vision-beta": {
      "provider": "xai",
      "displayName": "Grok Vision Beta",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "webSearch": true
      }
    },
    "search_api": {
      "provider": "google",
      "displayName": "Search Api",
      "mode": "chat",
      "source": "litellm"
    },
    "sora-2": {
      "provider": "openai",
      "displayName": "Sora 2",
      "mode": "chat",
      "source": "litellm"
    },
    "sora-2-pro": {
      "provider": "openai",
      "displayName": "Sora 2 Pro",
      "mode": "chat",
      "source": "litellm"
    },
    "sora-2-pro-high-res": {
      "provider": "azure",
      "displayName": "Sora 2 Pro High Res",
      "mode": "chat",
      "source": "litellm"
    },
    "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Coder 480b A35b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4.5e-7,
        "outputCostPerToken": 0.0000018
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      },
      "capabilities": {
        "reasoning": true
      }
    },
    "accounts/fireworks/models/flux-kontext-pro": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/flux Kontext Pro",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 4e-8,
        "outputCostPerToken": 4e-8
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/SSD-1B": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/SSD 1B",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.3e-10,
        "outputCostPerToken": 1.3e-10
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/chronos-hermes-13b-v2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/chronos Hermes 13b V2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/code-llama-13b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 13b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/code-llama-13b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 13b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/code-llama-13b-python": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 13b Python",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/code-llama-34b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 34b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/code-llama-34b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 34b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/code-llama-34b-python": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 34b Python",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/code-llama-70b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 70b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/code-llama-70b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 70b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/code-llama-70b-python": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 70b Python",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/code-llama-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/code-llama-7b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 7b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/code-llama-7b-python": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Llama 7b Python",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/code-qwen-1p5-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/code Qwen 1p5 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 65536
      }
    },
    "accounts/fireworks/models/codegemma-2b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/codegemma 2b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/codegemma-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/codegemma 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/cogito-671b-v2-p1": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/cogito 671b V2 P1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 163840
      }
    },
    "accounts/fireworks/models/cogito-v1-preview-llama-3b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/cogito V1 Preview Llama 3b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/cogito-v1-preview-llama-70b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/cogito V1 Preview Llama 70b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/cogito-v1-preview-llama-8b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/cogito V1 Preview Llama 8b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/cogito-v1-preview-qwen-14b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/cogito V1 Preview Qwen 14b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/cogito-v1-preview-qwen-32b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/cogito V1 Preview Qwen 32b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/flux-kontext-max": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/flux Kontext Max",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 8e-8,
        "outputCostPerToken": 8e-8
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/dbrx-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/dbrx Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/deepseek-coder-1b-base": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek Coder 1b Base",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/deepseek-coder-33b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek Coder 33b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/deepseek-coder-7b-base": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek Coder 7b Base",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/deepseek-coder-7b-base-v1p5": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek Coder 7b Base V1p5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek Coder 7b Instruct V1p5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/deepseek-coder-v2-lite-base": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek Coder V2 Lite Base",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 163840
      }
    },
    "accounts/fireworks/models/deepseek-coder-v2-lite-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek Coder V2 Lite Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 163840
      }
    },
    "accounts/fireworks/models/deepseek-prover-v2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek Prover V2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 163840
      }
    },
    "accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek R1 0528 Distill Qwen3 8b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/deepseek-r1-distill-llama-70b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek R1 Distill Llama 70b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/deepseek-r1-distill-llama-8b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek R1 Distill Llama 8b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/deepseek-r1-distill-qwen-14b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek R1 Distill Qwen 14b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek R1 Distill Qwen 1p5b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/deepseek-r1-distill-qwen-32b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek R1 Distill Qwen 32b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/deepseek-r1-distill-qwen-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek R1 Distill Qwen 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/deepseek-v2-lite-chat": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek V2 Lite Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 163840
      }
    },
    "accounts/fireworks/models/deepseek-v2p5": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/deepseek V2p5",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/devstral-small-2505": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/devstral Small 2505",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/dobby Mini Unhinged Plus Llama 3 1 8b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/dobby Unhinged Llama 3 3 70b New",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/dolphin-2-9-2-qwen2-72b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/dolphin 2 9 2 Qwen2 72b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/dolphin-2p6-mixtral-8x7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/dolphin 2p6 Mixtral 8x7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/ernie-4p5-21b-a3b-pt": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/ernie 4p5 21b A3b Pt",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/ernie-4p5-300b-a47b-pt": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/ernie 4p5 300b A47b Pt",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/fare-20b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/fare 20b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/firefunction-v1": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/firefunction V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/firellava-13b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/firellava 13b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/firesearch-ocr-v6": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/firesearch Ocr V6",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/fireworks-asr-large": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/fireworks Asr Large",
      "mode": "audio_transcription",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/fireworks-asr-v2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/fireworks Asr V2",
      "mode": "audio_transcription",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/flux-1-dev": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/flux 1 Dev",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/flux-1-dev-controlnet-union": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/flux 1 Dev Controlnet Union",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-9,
        "outputCostPerToken": 1e-9
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/flux-1-dev-fp8": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/flux 1 Dev Fp8",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-10,
        "outputCostPerToken": 5e-10
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/flux-1-schnell": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/flux 1 Schnell",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/flux-1-schnell-fp8": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/flux 1 Schnell Fp8",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3.5e-10,
        "outputCostPerToken": 3.5e-10
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/gemma-2b-it": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/gemma 2b It",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/gemma-3-27b-it": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/gemma 3 27b It",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/gemma-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/gemma 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/gemma-7b-it": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/gemma 7b It",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/gemma2-9b-it": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/gemma2 9b It",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/glm-4p5v": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/glm 4p5v",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "reasoning": true
      }
    },
    "accounts/fireworks/models/gpt-oss-safeguard-120b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/gpt Oss Safeguard 120b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/gpt-oss-safeguard-20b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/gpt Oss Safeguard 20b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/hermes-2-pro-mistral-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/hermes 2 Pro Mistral 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/internvl3-38b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/internvl3 38b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/internvl3-78b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/internvl3 78b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/internvl3-8b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/internvl3 8b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/japanese-stable-diffusion-xl": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/japanese Stable Diffusion Xl",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.3e-10,
        "outputCostPerToken": 1.3e-10
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/kat-coder": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/kat Coder",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/kat-dev-32b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/kat Dev 32b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/kat-dev-72b-exp": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/kat Dev 72b Exp",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/llama-guard-2-8b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama Guard 2 8b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/llama-guard-3-1b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama Guard 3 1b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/llama-guard-3-8b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama Guard 3 8b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/llama-v2-13b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V2 13b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/llama-v2-13b-chat": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V2 13b Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/llama-v2-70b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V2 70b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/llama-v2-70b-chat": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V2 70b Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 2048,
        "maxOutputTokens": 2048
      }
    },
    "accounts/fireworks/models/llama-v2-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V2 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/llama-v2-7b-chat": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V2 7b Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/llama-v3-70b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3 70b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/llama-v3-70b-instruct-hf": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3 70b Instruct Hf",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/llama-v3-8b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3 8b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/llama-v3-8b-instruct-hf": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3 8b Instruct Hf",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/llama-v3p1-405b-instruct-long": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p1 405b Instruct Long",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/llama-v3p1-70b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p1 70b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/llama-v3p1-70b-instruct-1b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p1 70b Instruct 1b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p1 Nemotron 70b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/llama-v3p2-1b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p2 1b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/llama-v3p2-3b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p2 3b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/llama-v3p3-70b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llama V3p3 70b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/llamaguard-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llamaguard 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/llava-yi-34b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/llava Yi 34b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/minimax-m1-80k": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/minimax M1 80k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/minimax-m2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/minimax M2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 3e-7,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/ministral-3-14b-instruct-2512": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/ministral 3 14b Instruct 2512",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "accounts/fireworks/models/ministral-3-3b-instruct-2512": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/ministral 3 3b Instruct 2512",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "accounts/fireworks/models/ministral-3-8b-instruct-2512": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/ministral 3 8b Instruct 2512",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "accounts/fireworks/models/mistral-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mistral 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/mistral-7b-instruct-4k": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mistral 7b Instruct 4k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/mistral-7b-instruct-v0p2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mistral 7b Instruct V0p2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/mistral-7b-instruct-v3": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mistral 7b Instruct V3",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/mistral-7b-v0p2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mistral 7b V0p2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/mistral-large-3-fp8": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mistral Large 3 Fp8",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 256000
      }
    },
    "accounts/fireworks/models/mistral-nemo-base-2407": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mistral Nemo Base 2407",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      }
    },
    "accounts/fireworks/models/mistral-nemo-instruct-2407": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mistral Nemo Instruct 2407",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      }
    },
    "accounts/fireworks/models/mistral-small-24b-instruct-2501": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mistral Small 24b Instruct 2501",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/mixtral-8x22b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mixtral 8x22b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 65536
      }
    },
    "accounts/fireworks/models/mixtral-8x22b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mixtral 8x22b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0.0000012,
        "outputCostPerToken": 0.0000012
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 65536
      }
    },
    "accounts/fireworks/models/mixtral-8x7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mixtral 8x7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/mixtral-8x7b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mixtral 8x7b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/mixtral-8x7b-instruct-hf": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mixtral 8x7b Instruct Hf",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/mythomax-l2-13b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/mythomax L2 13b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/nemotron-nano-v2-12b-vl": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/nemotron Nano V2 12b Vl",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/nous-capybara-7b-v1p9": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/nous Capybara 7b V1p9",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/nous Hermes 2 Mixtral 8x7b Dpo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/nous-hermes-2-yi-34b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/nous Hermes 2 Yi 34b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/nous-hermes-llama2-13b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/nous Hermes Llama2 13b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/nous-hermes-llama2-70b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/nous Hermes Llama2 70b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/nous-hermes-llama2-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/nous Hermes Llama2 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/nvidia-nemotron-nano-12b-v2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/nvidia Nemotron Nano 12b V2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/nvidia-nemotron-nano-9b-v2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/nvidia Nemotron Nano 9b V2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/openchat-3p5-0106-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/openchat 3p5 0106 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/openhermes-2-mistral-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/openhermes 2 Mistral 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/openhermes-2p5-mistral-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/openhermes 2p5 Mistral 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/openorca-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/openorca 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/phi-2-3b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/phi 2 3b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 2048,
        "maxOutputTokens": 2048
      }
    },
    "accounts/fireworks/models/phi-3-mini-128k-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/phi 3 Mini 128k Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/phi-3-vision-128k-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/phi 3 Vision 128k Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32064,
        "maxOutputTokens": 32064
      }
    },
    "accounts/fireworks/models/phind-code-llama-34b-python-v1": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/phind Code Llama 34b Python V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/phind-code-llama-34b-v1": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/phind Code Llama 34b V1",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/phind-code-llama-34b-v2": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/phind Code Llama 34b V2",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/playground-v2-1024px-aesthetic": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/playground V2 1024px Aesthetic",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.3e-10,
        "outputCostPerToken": 1.3e-10
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/playground-v2-5-1024px-aesthetic": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/playground V2 5 1024px Aesthetic",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.3e-10,
        "outputCostPerToken": 1.3e-10
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/pythia-12b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/pythia 12b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 2048,
        "maxOutputTokens": 2048
      }
    },
    "accounts/fireworks/models/qwen-qwq-32b-preview": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen Qwq 32b Preview",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen-v2p5-14b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen V2p5 14b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen-v2p5-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen V2p5 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/qwen1p5-72b-chat": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen1p5 72b Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2-7b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2 7b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2-vl-2b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2 Vl 2b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2-vl-72b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2 Vl 72b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2-vl-7b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2 Vl 7b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-0p5b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 0p5b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-14b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 14b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/qwen2p5-1p5b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 1p5b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-32b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 32b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/qwen2p5-32b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 32b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-72b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 72b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/qwen2p5-72b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 72b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-7b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 7b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-0p5b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 0p5b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-0p5b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 0p5b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-14b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 14b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-14b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 14b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-1p5b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 1p5b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-1p5b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 1p5b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-32b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 32b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 32b Instruct 128k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 32b Instruct 32k Rope",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 32b Instruct 64k",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 65536,
        "maxOutputTokens": 65536
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-3b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 3b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-3b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 3b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-coder-7b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Coder 7b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen2p5-math-72b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Math 72b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/qwen2p5-vl-32b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Vl 32b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      }
    },
    "accounts/fireworks/models/qwen2p5-vl-3b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Vl 3b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      }
    },
    "accounts/fireworks/models/qwen2p5-vl-72b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Vl 72b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      }
    },
    "accounts/fireworks/models/qwen2p5-vl-7b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen2p5 Vl 7b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      }
    },
    "accounts/fireworks/models/qwen3-0p6b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 0p6b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 40960,
        "maxOutputTokens": 40960
      }
    },
    "accounts/fireworks/models/qwen3-14b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 14b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 40960,
        "maxOutputTokens": 40960
      }
    },
    "accounts/fireworks/models/qwen3-1p7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 1p7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/qwen3-1p7b-fp8-draft": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 1p7b Fp8 Draft",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 1p7b Fp8 Draft 131072",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 1p7b Fp8 Draft 40960",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 40960,
        "maxOutputTokens": 40960
      }
    },
    "accounts/fireworks/models/qwen3-235b-a22b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 235b A22b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.2e-7,
        "outputCostPerToken": 8.8e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/qwen3-235b-a22b-instruct-2507": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 235b A22b Instruct 2507",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.2e-7,
        "outputCostPerToken": 8.8e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-235b-a22b-thinking-2507": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 235b A22b Thinking 2507",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.2e-7,
        "outputCostPerToken": 8.8e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-30b-a3b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 30b A3b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/qwen3-30b-a3b-instruct-2507": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 30b A3b Instruct 2507",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 5e-7,
        "outputCostPerToken": 5e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-30b-a3b-thinking-2507": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 30b A3b Thinking 2507",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-32b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 32b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "reasoning": true
      }
    },
    "accounts/fireworks/models/qwen3-4b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 4b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 40960,
        "maxOutputTokens": 40960
      }
    },
    "accounts/fireworks/models/qwen3-4b-instruct-2507": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 4b Instruct 2507",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-8b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 8b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 40960,
        "maxOutputTokens": 40960
      },
      "capabilities": {
        "reasoning": true
      }
    },
    "accounts/fireworks/models/qwen3-coder-30b-a3b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Coder 30b A3b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-coder-480b-instruct-bf16": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Coder 480b Instruct Bf16",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/qwen3-embedding-0p6b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Embedding 0p6b",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/qwen3-embedding-4b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Embedding 4b",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 40960,
        "maxOutputTokens": 40960
      }
    },
    "accounts/fireworks/models/": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/",
      "mode": "embedding",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 40960,
        "maxOutputTokens": 40960
      }
    },
    "accounts/fireworks/models/qwen3-next-80b-a3b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Next 80b A3b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/qwen3-next-80b-a3b-thinking": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Next 80b A3b Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/qwen3-reranker-0p6b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Reranker 0p6b",
      "mode": "rerank",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 40960,
        "maxOutputTokens": 40960
      }
    },
    "accounts/fireworks/models/qwen3-reranker-4b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Reranker 4b",
      "mode": "rerank",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 40960,
        "maxOutputTokens": 40960
      }
    },
    "accounts/fireworks/models/qwen3-reranker-8b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Reranker 8b",
      "mode": "rerank",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 40960,
        "maxOutputTokens": 40960
      }
    },
    "accounts/fireworks/models/qwen3-vl-235b-a22b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Vl 235b A22b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.2e-7,
        "outputCostPerToken": 8.8e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-vl-235b-a22b-thinking": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Vl 235b A22b Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2.2e-7,
        "outputCostPerToken": 8.8e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-vl-30b-a3b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Vl 30b A3b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-vl-30b-a3b-thinking": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Vl 30b A3b Thinking",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 262144,
        "maxOutputTokens": 262144
      }
    },
    "accounts/fireworks/models/qwen3-vl-32b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Vl 32b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/qwen3-vl-8b-instruct": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwen3 Vl 8b Instruct",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/qwq-32b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/qwq 32b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      }
    },
    "accounts/fireworks/models/rolm-ocr": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/rolm Ocr",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 128000
      }
    },
    "accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/snorkel Mistral 7b Pairrm Dpo",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/stable-diffusion-xl-1024-v1-0": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/stable Diffusion Xl 1024 V1 0",
      "mode": "image_generation",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1.3e-10,
        "outputCostPerToken": 1.3e-10
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/stablecode-3b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/stablecode 3b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/starcoder-16b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/starcoder 16b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/starcoder-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/starcoder 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 8192
      }
    },
    "accounts/fireworks/models/starcoder2-15b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/starcoder2 15b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/starcoder2-3b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/starcoder2 3b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 1e-7,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/starcoder2-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/starcoder2 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 16384,
        "maxOutputTokens": 16384
      }
    },
    "accounts/fireworks/models/toppy-m-7b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/toppy M 7b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "accounts/fireworks/models/whisper-v3": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/whisper V3",
      "mode": "audio_transcription",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/whisper-v3-turbo": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/whisper V3 Turbo",
      "mode": "audio_transcription",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/yi-34b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/yi 34b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/yi-34b-200k-capybara": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/yi 34b 200k Capybara",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 200000
      }
    },
    "accounts/fireworks/models/yi-34b-chat": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/yi 34b Chat",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 9e-7,
        "outputCostPerToken": 9e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/yi-6b": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/yi 6b",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 4096,
        "maxOutputTokens": 4096
      }
    },
    "accounts/fireworks/models/zephyr-7b-beta": {
      "provider": "fireworks_ai",
      "displayName": "Accounts/fireworks/models/zephyr 7b Beta",
      "mode": "chat",
      "source": "litellm",
      "pricing": {
        "inputCostPerToken": 2e-7,
        "outputCostPerToken": 2e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      }
    },
    "claude-opus-4.6": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude Opus 4.6",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-v3.2-speciale": {
      "provider": "deepseek",
      "displayName": "DeepSeek: DeepSeek V3.2 Speciale",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 2.7e-7,
        "outputCostPerToken": 4.1e-7
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "claude-opus-4.5": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude Opus 4.5",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k"
      ],
      "pricing": {
        "inputCostPerToken": 0.000005,
        "outputCostPerToken": 0.000025
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "sonar-pro-search": {
      "provider": "perplexity",
      "displayName": "Perplexity: Sonar Pro Search",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8000
      },
      "capabilities": {
        "vision": true
      }
    },
    "gpt-oss-safeguard-20b": {
      "provider": "openai",
      "displayName": "OpenAI: gpt-oss-safeguard-20b",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 7.5e-8,
        "outputCostPerToken": 3e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "gpt-5-image-mini": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5 Image Mini",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 400000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "claude-haiku-4.5": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude Haiku 4.5",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000001,
        "outputCostPerToken": 0.000005
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "gpt-5-image": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-5 Image",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.00001,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 400000,
        "maxOutputTokens": 128000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "claude-sonnet-4.5": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude Sonnet 4.5",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-v3.2-exp": {
      "provider": "deepseek",
      "displayName": "DeepSeek: DeepSeek V3.2 Exp",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 2.7e-7,
        "outputCostPerToken": 4.1e-7
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-v3.1-terminus:exacto": {
      "provider": "deepseek",
      "displayName": "DeepSeek: DeepSeek V3.1 Terminus (exacto)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 2.1e-7,
        "outputCostPerToken": 7.9e-7
      },
      "context": {
        "maxInputTokens": 163840
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-v3.1-terminus": {
      "provider": "deepseek",
      "displayName": "DeepSeek: DeepSeek V3.1 Terminus",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 2.1e-7,
        "outputCostPerToken": 7.9e-7
      },
      "context": {
        "maxInputTokens": 163840
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-chat-v3.1": {
      "provider": "deepseek",
      "displayName": "DeepSeek: DeepSeek V3.1",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 7.5e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 7168
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "gpt-oss-120b:free": {
      "provider": "openai",
      "displayName": "OpenAI: gpt-oss-120b (free)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature"
      ],
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "gpt-oss-120b": {
      "provider": "openai",
      "displayName": "OpenAI: gpt-oss-120b",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 3.9e-8,
        "outputCostPerToken": 1.9e-7
      },
      "context": {
        "maxInputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "gpt-oss-120b:exacto": {
      "provider": "openai",
      "displayName": "OpenAI: gpt-oss-120b (exacto)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 3.9e-8,
        "outputCostPerToken": 1.9e-7
      },
      "context": {
        "maxInputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "gpt-oss-20b:free": {
      "provider": "openai",
      "displayName": "OpenAI: gpt-oss-20b (free)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature"
      ],
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true
      }
    },
    "gpt-oss-20b": {
      "provider": "openai",
      "displayName": "OpenAI: gpt-oss-20b",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 3e-8,
        "outputCostPerToken": 1.4e-7
      },
      "context": {
        "maxInputTokens": 131072
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "claude-opus-4.1": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude Opus 4.1",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 32000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "gemma-3n-e2b-it:free": {
      "provider": "google",
      "displayName": "Google: Gemma 3n 2B (free)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "gemini-2.5-pro-preview": {
      "provider": "google",
      "displayName": "Google: Gemini 2.5 Pro Preview 06-05",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.00000125,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 1048576,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "vision": true,
        "audioInput": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-r1-0528:free": {
      "provider": "deepseek",
      "displayName": "DeepSeek: R1 0528 (free)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 163840
      }
    },
    "deepseek-r1-0528": {
      "provider": "deepseek",
      "displayName": "DeepSeek: R1 0528",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 4e-7,
        "outputCostPerToken": 0.00000175
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "claude-opus-4": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude Opus 4",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000015,
        "outputCostPerToken": 0.000075
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 32000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "claude-sonnet-4": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude Sonnet 4",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 1000000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "gemma-3n-e4b-it:free": {
      "provider": "google",
      "displayName": "Google: Gemma 3n 4B (free)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "gemma-3n-e4b-it": {
      "provider": "google",
      "displayName": "Google: Gemma 3n 4B",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 2e-8,
        "outputCostPerToken": 4e-8
      },
      "context": {
        "maxInputTokens": 32768
      }
    },
    "o4-mini-high": {
      "provider": "openai",
      "displayName": "OpenAI: o4 Mini High",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens"
      ],
      "pricing": {
        "inputCostPerToken": 0.0000011,
        "outputCostPerToken": 0.0000044
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-chat-v3-0324": {
      "provider": "deepseek",
      "displayName": "DeepSeek: DeepSeek V3 0324",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 1.9e-7,
        "outputCostPerToken": 8.7e-7
      },
      "context": {
        "maxInputTokens": 163840,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "gemma-3-4b-it:free": {
      "provider": "google",
      "displayName": "Google: Gemma 3 4B (free)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "structuredOutput": true
      }
    },
    "gemma-3-4b-it": {
      "provider": "google",
      "displayName": "Google: Gemma 3 4B",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 1.703012e-8,
        "outputCostPerToken": 6.81536e-8
      },
      "context": {
        "maxInputTokens": 96000
      },
      "capabilities": {
        "vision": true,
        "structuredOutput": true
      }
    },
    "gemma-3-12b-it:free": {
      "provider": "google",
      "displayName": "Google: Gemma 3 12B (free)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true
      }
    },
    "gemma-3-12b-it": {
      "provider": "google",
      "displayName": "Google: Gemma 3 12B",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 3e-8,
        "outputCostPerToken": 1e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "vision": true,
        "structuredOutput": true
      }
    },
    "command-a": {
      "provider": "cohere",
      "displayName": "Cohere: Command A",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 256000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "gemma-3-27b-it:free": {
      "provider": "google",
      "displayName": "Google: Gemma 3 27B (free)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0,
        "outputCostPerToken": 0
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "gemma-3-27b-it": {
      "provider": "google",
      "displayName": "Google: Gemma 3 27B",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 4e-8,
        "outputCostPerToken": 1.5e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 65536
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "claude-3.7-sonnet:thinking": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude 3.7 Sonnet (thinking)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "claude-3.7-sonnet": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude 3.7 Sonnet",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000003,
        "outputCostPerToken": 0.000015
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "o3-mini-high": {
      "provider": "openai",
      "displayName": "OpenAI: o3 Mini High",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens"
      ],
      "pricing": {
        "inputCostPerToken": 0.0000011,
        "outputCostPerToken": 0.0000044
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 100000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "deepseek-r1-distill-qwen-32b": {
      "provider": "deepseek",
      "displayName": "DeepSeek: R1 Distill Qwen 32B",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 2.9e-7,
        "outputCostPerToken": 2.9e-7
      },
      "context": {
        "maxInputTokens": 32768,
        "maxOutputTokens": 32768
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "deepseek-r1-distill-llama-70b": {
      "provider": "deepseek",
      "displayName": "DeepSeek: R1 Distill Llama 70B",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 3e-8,
        "outputCostPerToken": 1.1e-7
      },
      "context": {
        "maxInputTokens": 131072,
        "maxOutputTokens": 131072
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "command-r7b-12-2024": {
      "provider": "cohere",
      "displayName": "Cohere: Command R7B (12-2024)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 3.75e-8,
        "outputCostPerToken": 1.5e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4000
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "claude-3.5-haiku": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude 3.5 Haiku",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 8e-7,
        "outputCostPerToken": 0.000004
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "claude-3.5-sonnet": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude 3.5 Sonnet",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000006,
        "outputCostPerToken": 0.00003
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 8192
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "command-r-08-2024": {
      "provider": "cohere",
      "displayName": "Cohere: Command R (08-2024)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 1.5e-7,
        "outputCostPerToken": 6e-7
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "command-r-plus-08-2024": {
      "provider": "cohere",
      "displayName": "Cohere: Command R+ (08-2024)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.0000025,
        "outputCostPerToken": 0.00001
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 4000
      },
      "capabilities": {
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "gemma-2-27b-it": {
      "provider": "google",
      "displayName": "Google: Gemma 2 27B",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 6.5e-7,
        "outputCostPerToken": 6.5e-7
      },
      "context": {
        "maxInputTokens": 8192,
        "maxOutputTokens": 2048
      },
      "capabilities": {
        "structuredOutput": true
      }
    },
    "gemma-2-9b-it": {
      "provider": "google",
      "displayName": "Google: Gemma 2 9B",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 3e-8,
        "outputCostPerToken": 9e-8
      },
      "context": {
        "maxInputTokens": 8192
      }
    },
    "gpt-4o:extended": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-4o (extended)",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.000006,
        "outputCostPerToken": 0.000018
      },
      "context": {
        "maxInputTokens": 128000,
        "maxOutputTokens": 64000
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true,
        "structuredOutput": true
      }
    },
    "claude-3-haiku": {
      "provider": "anthropic",
      "displayName": "Anthropic: Claude 3 Haiku",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "max_tokens",
        "temperature",
        "top_k",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 2.5e-7,
        "outputCostPerToken": 0.00000125
      },
      "context": {
        "maxInputTokens": 200000,
        "maxOutputTokens": 4096
      },
      "capabilities": {
        "vision": true,
        "functionCalling": true
      }
    },
    "gpt-3.5-turbo-instruct": {
      "provider": "openai",
      "displayName": "OpenAI: GPT-3.5 Turbo Instruct",
      "mode": "chat",
      "source": "openrouter",
      "supportedParameters": [
        "frequency_penalty",
        "max_tokens",
        "presence_penalty",
        "temperature",
        "top_p"
      ],
      "pricing": {
        "inputCostPerToken": 0.0000015,
        "outputCostPerToken": 0.000002
      },
      "context": {
        "maxInputTokens": 4095,
        "maxOutputTokens": 4095
      },
      "capabilities": {
        "structuredOutput": true
      }
    }
  }
}