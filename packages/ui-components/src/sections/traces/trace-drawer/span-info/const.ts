export const SpanAttributeKeys = {
  REQUEST_MODEL: "gen_ai.request.model",
  AI_PROMPT_MESSAGES: "ai.prompt.messages",
  AI_PROMPT: "ai.prompt",
  AI_MODEL_ID: "ai.model.id",
  AI_OPERATION_ID: "ai.operationId",
  AI_OPERATION_NAME: "operation.name",
  AI_MODEL_PROVIDER: "ai.model.provider",
  GEN_AI_REQUEST_MAX_TOKENS: "gen_ai.request.max_tokens",
  AI_SETTINGS_MAX_TOKENS: "ai.settings.maxTokens",
  GEN_AI_REQUEST_TEMPERATURE: "gen_ai.request.temperature",
  AI_SETTINGS_TEMPERATURE: "ai.settings.temperature",
  GEN_AI_REQUEST_TOP_P: "gen_ai.request.top_p",
  AI_SETTINGS_TOP_P: "ai.settings.topP",
  GEN_AI_REQUEST_PRESENCE_PENALTY: "gen_ai.request.presence_penalty",
  AI_SETTINGS_PRESENCE_PENALTY: "ai.settings.presencePenalty",
  AI_TOOL_CALL_NAME: "ai.toolCall.name",
  AI_TOOL_CALL_ID: "ai.toolCall.id",
  AI_TOOL_CALL_ARGS: "ai.toolCall.args",
  AI_TOOL_CALL_RESULT: "ai.toolCall.result",
  AI_TELEMETRY_METADATA_PREFIX: "ai.telemetry.metadata.",
  AI_TELEMETRY_METADATA_PROPS: "ai.telemetry.metadata.props",
  AI_RESPONSE_FINISH_REASON: "ai.response.finishReason",
  GEN_AI_RESPONSE_FINISH_REASONS: "gen_ai.response.finish_reasons",
  AI_RESPONSE_TEXT: "ai.response.text",
  AI_RESPONSE_OBJECT: "ai.response.object",
  GEN_AI_USAGE_INPUT_TOKENS: "gen_ai.usage.input_tokens",
  AI_USAGE_PROMPT_TOKENS: "ai.usage.promptTokens",
  GEN_AI_USAGE_OUTPUT_TOKENS: "gen_ai.usage.output_tokens",
  AI_USAGE_COMPLETION_TOKENS: "ai.usage.completionTokens",
  GEN_AI_USAGE_COST: "gen_ai.usage.cost",
  AI_RESPONSE_TOOL_CALLS: "ai.response.toolCalls",
};
